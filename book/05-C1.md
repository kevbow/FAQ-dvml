# Classification 1





## Classification in General

### **Pada kasus klasifikasi, penentuan kelas didasarkan pada peluang. Bagaimana jika peluang yang diperoleh sama besar, misalnya pada kasus klasifikasi biner diperoleh peluang masuk ke kelas positif adalah 0.5 dan peluang masuk ke kelas negatif juga 0.5?**

Hal tersebut bergantung pada user yang menentukan threshold/batasan probability untuk masuk ke kelas positif atau masuk ke kelas negatif. Namun, pada umumnya jika diperoleh probability $>= 0.5$ maka observasi tersebut akan masuk ke kelas positif.

### **Permasalahan apa yang paling sering ditemui pada kasus klasifikasi?**

Permasalahan yang sering ditemui pada kasus klasifikasi adalah proporsi target variabel yang tidak seimbang. Pada data di lapangan, nyatanya jumlah kelas positif jauh lebih sedikit dibandingkan kelas negatif. Contohnya:
   
   - Perbankan: fraud detection, loan default
   - Penerbangan: delay prediction
   - Digital marketing: customer churn
   - Kesehatan: cancer detection
   - HR: employee attrition
   - dan masih banyak lagi

Misalkan pada kasus fraud detection, dari 1000 transaksi yang terjadi, hanya 10 diantaranya fraud. Hal tersebut akan berpengaruh terhadap kemampuan model untuk memprediksi target, karena model klasifikasi sangat bergantung pada jumlah setiap level target dalam proses learning-nya. Model klasifikasi cenderung lebih pintar dalam memprediksi kelas mayoritas. Hal ini menjadi masalah yang cukup serius, sehingga perlu dilakukan penanganan lebih lanjut.
   
![](assets/04-C1/imbalance proportion.png)


```r
attrition <- read_csv("data/04-C1/attrition.csv") %>% 
  mutate(attrition = as.factor(attrition))

prop.table(table(attrition$attrition)) %>% round(2)
```

```
#> 
#>   no  yes 
#> 0.84 0.16
```

Salah satu cara yang paling umum untuk menyeimbangkan proporsi target variabel adalah dengan metode sampling, yaitu **downsampling** dan **upsampling**.

- **Downsampling** adalah proses sampling pada observasi kelas mayoritas sebanyak jumlah observasi pada kelas minoritas. Proses downsampling akan mengurangi jumlah observasi pada kelas mayoritas, sehingga memungkinkan terjadinya kehilangan informasi.

- **Upsampling** adalah proses sampling pada observasi kelas minoritas sebanyak jumlah observasi pada kelas mayoritas. Proses upsampling akan menambah jumlah observasi pada kelas minoritas, sehingga hanya menduplikasi data yang terdapat pada kelas minoritas.

Berikut contoh downsampling dan upsampling dengan menggunakan fungsi pada library `caret` dan `recipes`:

Sebelum menerapkan downsampling dan upsampling terlebih dahulu dilakukan cross validation, yaitu membagi data menjadi **training set** untuk proses pemodelan dan **testing set** untuk melakukan evaluasi. Cross validation dilakukan dengan menggunakan fungsi `initial_split()` dari library `rsample`. Fungsi tersebut akan melakukan proses sampling dengan metode **stratified random sampling**, sehingga proporsi target variabel pada data awal dipertahankan dengan baik pada training set maupun testing set.


```r
# define seed
set.seed(100)

# menentukan indeks untuk train dan test
splitted <- initial_split(data = attrition,
                          prop = 0.75,
                          strata = "attrition")

# mengambil indeks data train
train <- training(splitted)

# mengambil indeks data test`
test <- testing(splitted)
```


```r
# proporsi data train
prop.table(table(train$attrition)) %>% round(2)
```

```
#> 
#>   no  yes 
#> 0.84 0.16
```


```r
# proporsi data test
prop.table(table(test$attrition)) %>% round(2)
```

```
#> 
#>   no  yes 
#> 0.84 0.16
```

> Downsampling dan upsampling **hanya dilakukan pada data train** karena proses pembuatan model klasifikasi hanya dilakukan pada data train. Data test dianggap sebagai unseen data yang hanya digunakan untuk mengevaluasi model.

- Cara downsampling menggunakan `downSample()` dari library `caret`


```r
train_down <- downSample(x = train[, -1],
                         y = train$attrition,
                         yname = "attrition")
```


```r
prop.table(table(train_down$attrition)) %>% round(2)
```

```
#> 
#>  no yes 
#> 0.5 0.5
```

- Cara upsampling menggunakan `upSample()` dari library `caret`


```r
train_up <- upSample(x = train[, -1],
                     y = train$attrition,
                     yname = "attrition")
```


```r
prop.table(table(train_up$attrition)) %>% round(2)
```

```
#> 
#>  no yes 
#> 0.5 0.5
```

Berikut dokumentasi official dari library `caret`: [downSample: Down- and Up-Sampling Imbalanced Data](https://rdrr.io/cran/caret/man/downSample.html)

- Cara downsampling/upsampling dengan `recipes`

Seperti saat menggunakan fungsi pada library `caret`, ketika menggunakan fungsi dari library `recipes` juga harus dilakukan cross validation terlebih dahulu. Perbedaan ketika menggunakan fungsi dari library `recipes` adalah data train dan test tidak di-assign ke dalam sebuah objek melainkan dilakukan downsampling atau upsampling terlebih dahulu.


```r
set.seed(417)

splitted_rec <- initial_split(data = attrition,
                              prop = 0.8,
                              strata = "attrition")

splitted_rec
```

```
#> <Analysis/Assess/Total>
#> <1177/293/1470>
```

Gunakan fungsi `step_downsample()` atau `step_upsample()` yang didefinisikan dalam sebuah **recipe**.


```r
rec <- recipe(attrition ~ ., training(splitted)) %>% 
  
  # `step_downsample()` dapat diganti dengan `step_upsample()`
  step_downsample(attrition, ratio = 1, seed = 100) %>%
  
  prep()
```


```r
# membuat data train dengan fungsi `juice()`
train_rec <- juice(rec)

# membuat data test dengan fungsi `bake()`
test_rec <- bake(rec, testing(splitted))
```


```r
prop.table(table(train_rec$attrition)) %>% round(2)
```

```
#> 
#>  no yes 
#> 0.5 0.5
```

Berikut dokumentasi official dari library `recipes`: [tidymodels/recipes](https://github.com/tidymodels/recipes)

## Logistic Regression

### **Bagaimana model logistic regression menggunakan variabel kategorik sebagai prediktor?**

Sama seperti kasus linear regression, pada logistic regression variabel kategorik harus diubah menjadi dummy variabel. Pada fungsi `glm()` sudah otomatis melakukan transformasi dummy variabel untuk kolom yang bertipe data character atau factor.

### **Bagaimana jika terdapat salah satu level pada prediktor kategorik yang tidak signifikan (p-value > alpha)? Apakah prediktor tersebut masih dianggap signifikan mempengaruhi target?**

Level yang menjadi basis akan dianggap signifikan, sedangkan untuk level lainnya yang tidak signifikan artinya level tersebut tidak memberikan pengaruh terhadap target variabel. Solusi yang dapat dilakukan adalah:

  - Binning, yaitu level tersebut digabungkan dengan level lainnya yang mirip dan signifikan
  - Menambahkan jumlah observasi pada level yang tidak signifikan tersebut.   

### **Pada fungsi `lm()` sudah otomatis melakukan transformasi data kategorik dengan level pertama yang dijadikan basis. Apakah pengubahan urutan level (reorder) akan mengubah hasil pemodelan?**

Nilai p-value pada setiap level tidak akan berubah ketika kita melakukan reorder level. Interpretasi untuk variabel kategorik bergantung pada level yang dijadikan basis.

### **Apa pengertian dari Null Deviance dan Residual Deviance pada summary model?**

- Null deviance menunjukkan seberapa baik model memprediksi target variabel hanya berdasarkan nilai intercept, tidak menggunakan predictor apapun.
- Residual deviance menunjukkan seberapa baik model memprediksi target variabel berdasarkan nilai intercept dan semua prediktor yang digunakan dalam model. Umumnya nilai Residual deviance lebih kecil dibandingkan null deviance.

Note: Null dan residual deviance hanya sebagian kecil tools yang bisa kita gunakan untuk mengevaluasi model mana yang paling baik. Namun perlu dijadikan catatan bahwa semakin banyak prediktor yang digunakan, nilai residual deviance pasti lebih kecil sehingga evaluasi menjadi bias. Pada praktiknya, confusion matrix lebih sering digunakan untuk melakukan evaluasi model klasifikasi.

Berikut link eksternal yang dapat dijadikan sebagai bahan referensi: [Null deviance & Residual deviance](https://www.theanalysisfactor.com/r-glm-model-fit/)

### **Apa itu Fisher Scoring pada summary model?**

Fisher scoring adalah turunan dari metode Newton untuk mengatasi Maximum Likelihood. Fisher scoring memberikan informasi berapa banyak iterasi yang dilakukan pada model sehingga diperoleh nilai parameter pada summary.

### **Apa itu Maximum Likelihood Estimator (MLE)?**

Nilai estimate pada model logistic regression diperoleh dengan pendekatan MLE. MLE merupakan pendekatan statistik untuk mendapatkan nilai estimate yang optimum pada model.

### **Apa yang dimaksud dari nilai Akaike Information Criterion (AIC)?**

AIC menggambarkan seberapa banyak informasi yang hilang pada model tersebut. Nilai AIC sendiri tidak dapat diinterpretasi, berbeda dengan R-squared, karena tidak memiliki range tertentu. Sehingga Nilai AIC digunakan untuk membandingkan kualitas dari beberapa model. Semakin kecil nilai AIC, semakin sedikit informasi yang hilang, yang artinya semakin baik model kita dalam menangkap pola data.

### **Bagaimana cara untuk mengindikasi adanya perfect separation pada model?**

- Tidak ada prediktor yang signifikan padahal nilai AIC sangat kecil   
- Terdapat 1 nilai estimate yang nilainya cukup besar dibandingkan yang lain   
- Gunakan parameter `method = "detect_separation"` untuk mendeteksi adanya perfect separation pada model:


```r
honors <- read.csv("data/04-C1/sample.csv")
```


```r
library(brglm2)
glm(hon ~ female + read + math + write,
    data = honors,
    family = "binomial",
    method = "detect_separation")
```

```
#> Separation: TRUE 
#> Existence of maximum likelihood estimates
#> (Intercept)      female        read        math       write 
#>        -Inf        -Inf        -Inf        -Inf         Inf 
#> 0: finite value, Inf: infinity, -Inf: -infinity
```

Output `Separation: TRUE` menandakan adanya perfect separation pada model. Untuk mengetahui variabel mana yang merupakan perfect separation, kita perlu amati output dari `summary()` model.

### **Bagaimana Logistic Regression untuk kasus multiclass classification?**

Multiclass classification adalah kasus klasifikasi dengan lebih dari 2 levels pada target variable. Contohnya pada data `iris` kita ingin mengklasifikasi apakah sebuah bunga termasuk kelas setosa, versicolor, atau virginica.


```r
levels(iris$Species)
```

```
#> [1] "setosa"     "versicolor" "virginica"
```

Lakukan train-test splitting dengan proporsi 80-20 persen.


```r
set.seed(100)
idx <- sample(nrow(iris), 0.8*nrow(iris))
iris_train <- iris[idx,]
iris_test <- iris[-idx,]
```

Pembuatan model multiclass classification dapat menggunakan fungsi `multinom()` dari library `nnet`, dengan menyertakan parameter `formula` dan `data`.


```r
library(nnet)
iris_multi <- multinom(formula = Species ~ ., data = iris_train)
```

```
#> # weights:  18 (10 variable)
#> initial  value 131.833475 
#> iter  10 value 12.613035
#> iter  20 value 1.598061
#> iter  30 value 0.583494
#> iter  40 value 0.373022
#> iter  50 value 0.306030
#> iter  60 value 0.267677
#> iter  70 value 0.236148
#> iter  80 value 0.196360
#> iter  90 value 0.125961
#> iter 100 value 0.120334
#> final  value 0.120334 
#> stopped after 100 iterations
```

```r
summary(iris_multi)
```

```
#> Call:
#> multinom(formula = Species ~ ., data = iris_train)
#> 
#> Coefficients:
#>            (Intercept) Sepal.Length Sepal.Width Petal.Length Petal.Width
#> versicolor    30.78627    -9.027769   -6.721883     16.02937   -8.216299
#> virginica    -52.10505   -45.676726  -55.277893     88.90439   48.300727
#> 
#> Std. Errors:
#>            (Intercept) Sepal.Length Sepal.Width Petal.Length Petal.Width
#> versicolor    475.4254     102.3678    105.1483     182.5314    297.8557
#> virginica     945.3978     173.0019    138.9215     376.6561    420.8273
#> 
#> Residual Deviance: 0.2406676 
#> AIC: 20.24067
```

Dari model summary di atas, kita dapat menuliskan formula logistic regression sebagai berikut:

$$log-odds(versicolor) = 30.78627 - 9.027769 Sepal.Length - 6.721883 Sepal.Width + 16.02937 Petal.Length - 8.216299 Petal.Width$$

$$log-odds(virginica) = -52.10505 - 45.676726 Sepal.Length - 55.277893 Sepal.Width + 88.90439 Petal.Length + 48.300727 Petal.Width$$

dengan $$Prob(setosa) = 1 - Prob(versicolor) - Prob(virginica)$$

Gunakan fungsi `predict()` dengan parameter `type = "probs"` untuk mengembalikan nilai probabilitas untuk masing-masing kelas. 


```r
iris_pred_prob <- predict(iris_multi,
                          newdata = iris_test,
                          type = "probs")

data.frame(iris_pred_prob) %>% round(8)
```

```
#>         setosa versicolor virginica
#> 1   0.99999998 0.00000002 0.0000000
#> 6   1.00000000 0.00000000 0.0000000
#> 10  0.99998435 0.00001565 0.0000000
#> 11  1.00000000 0.00000000 0.0000000
#> 13  0.99998478 0.00001522 0.0000000
#> 21  0.99999975 0.00000025 0.0000000
#> 33  1.00000000 0.00000000 0.0000000
#> 34  1.00000000 0.00000000 0.0000000
#> 38  0.99999989 0.00000011 0.0000000
#> 39  0.99995016 0.00004984 0.0000000
#> 50  0.99999985 0.00000015 0.0000000
#> 64  0.00000000 1.00000000 0.0000000
#> 67  0.00000000 1.00000000 0.0000000
#> 72  0.00003258 0.99996742 0.0000000
#> 73  0.00000000 0.00123755 0.9987624
#> 74  0.00000000 1.00000000 0.0000000
#> 76  0.00004259 0.99995741 0.0000000
#> 77  0.00000011 0.99999989 0.0000000
#> 79  0.00000004 0.99999996 0.0000000
#> 84  0.00000000 0.00000000 1.0000000
#> 90  0.00000002 0.99999998 0.0000000
#> 101 0.00000000 0.00000000 1.0000000
#> 103 0.00000000 0.00000000 1.0000000
#> 106 0.00000000 0.00000000 1.0000000
#> 108 0.00000000 0.00000000 1.0000000
#> 109 0.00000000 0.00000000 1.0000000
#> 117 0.00000000 0.00000000 1.0000000
#> 131 0.00000000 0.00000000 1.0000000
#> 134 0.00000000 0.00122746 0.9987725
#> 145 0.00000000 0.00000000 1.0000000
```

## Model Evaluation

### **Apa yang dimaksud dengan False Positive dan False Negative?**

- False positive adalah kasus dimana observasi di kelas negatif terprediksi oleh model sebagai positif. Contohnya, pasien yang sebenarnya mengidap kanker jinak, terprediksi oleh model sebagai kanker ganas.
- False negative adalah kasus dimana observasi di kelas positif terprediksi oleh model sebagai negatif. Contohnya, pasien yang sebenarnya mengidap kanker ganas, terprediksi oleh model sebagai kanker jinak.

### **Pada kasus klasifikasi, mengapa metric accuracy tidak cukup menjelaskan seberapa baik model yang diperoleh?**

Untuk mengetahui seberapa baik perfomance model klasifikasi, tidak cukup dengan melihat nilai accuracy nya saja, karena accuracy menganggap sama penting untuk kasus False Positive (FP) dan False Negative (FN). Apabila kasus FP dan Kita membutuhkan metric lain seperti Precision dan Recall.

Contoh pertama: pada kasus prediksi pasien apakah mengidap kanker jinak atau ganas. Tentunya akan lebih berbahaya apabila pasien dengan kanker ganas namun terprediksi menjadi jinak. Hal ini dapat membahayakan keselamatan pasien karena tidak ditangani dengan serius oleh pihak medis. Pada kasus ini ingin diminimalisir kasus terjadinya False Negative, maka kita mengharapkan nilai Recall yang lebih tinggi dibandingkan metric lainnya.

$$Recall = \frac{TP}{TP+FN}$$

Contoh kedua: pada kasus prediksi email apakah termasuk spam atau ham (tidak spam). Akan lebih berbahaya apabila email yang sebenarnya tidak spam namun terprediksi sebagai spam. Hal ini mengakibatkan email tidak spam akan masuk ke folder spam sehingga email penting tidak terbaca oleh pengguna. Pada kasus ini ingin diminimalisir kasus False Positive, maka kita mengharapkan nilai Precision yang tinggi dibandingkan metric lainnya.

$$Precision = \frac{TP}{TP+FP}$$

Apabila kedua metric Recall dan Precision sama-sama ingin diharapkan tinggi, dapat menggunakan metric F-score yang merupakan rata-rata harmonik dari Recall dan Precision:

$$F = 2 \times \frac{Precision \times Recall}{Precision + Recall}$$

### **Bagaimana cara melakukan penggeseran threshold pada kasus binary classification?**

Secara default, fungsi `predict()` menggunakan nilai 0.5 sebagai threshold dalam mengklasifikasi kelas positif dan negatif. Kita dapat menggeser nilai threshold tersebut untuk mendapatkan nilai Precision-Recall yang kita inginkan.

- Semakin besar threshold, maka Precision naik, Recall turun
- Semakin kecil threshold, maka Precision turun, Recall naik

Akan lebih praktis apabila kita dapat memvisualisasikan nilai Precision-Recall untuk setiap thresholdnya. Silahkan install package `cmplot` yang dikembangkan oleh [Ahmad Husain](https://github.com/ahmadhusain), salah satu instructor di Algoritma.


```r
install.packages("remotes")
remotes::install_github("ahmadhusain/cmplot")
```



Membuat plot "Tradeoff model performance" dari kasus apakah sebuah SMS diklasifikasi sebagai spam (kelas positif) atau ham (not spam, kelas negatif).


```r
library(cmplot)
confmat_plot(prob = model$predicted_prob,
             ref = model$actual_label,
             postarget = "spam",
             negtarget = "ham")
```

<!--html_preserve--><div id="htmlwidget-c9ed310b7e3b2c6b24e9" style="width:672px;height:480px;" class="plotly html-widget"></div>
<script type="application/json" data-for="htmlwidget-c9ed310b7e3b2c6b24e9">{"x":{"data":[{"x":[0.01,0.017979797979798,0.025959595959596,0.0339393939393939,0.0419191919191919,0.0498989898989899,0.0578787878787879,0.0658585858585859,0.0738383838383838,0.0818181818181818,0.0897979797979798,0.0977777777777778,0.105757575757576,0.113737373737374,0.121717171717172,0.12969696969697,0.137676767676768,0.145656565656566,0.153636363636364,0.161616161616162,0.16959595959596,0.177575757575758,0.185555555555556,0.193535353535354,0.201515151515152,0.20949494949495,0.217474747474748,0.225454545454545,0.233434343434343,0.241414141414141,0.249393939393939,0.257373737373737,0.265353535353535,0.273333333333333,0.281313131313131,0.289292929292929,0.297272727272727,0.305252525252525,0.313232323232323,0.321212121212121,0.329191919191919,0.337171717171717,0.345151515151515,0.353131313131313,0.361111111111111,0.369090909090909,0.377070707070707,0.385050505050505,0.393030303030303,0.401010101010101,0.408989898989899,0.416969696969697,0.424949494949495,0.432929292929293,0.440909090909091,0.448888888888889,0.456868686868687,0.464848484848485,0.472828282828283,0.480808080808081,0.488787878787879,0.496767676767677,0.504747474747475,0.512727272727273,0.520707070707071,0.528686868686869,0.536666666666667,0.544646464646465,0.552626262626263,0.560606060606061,0.568585858585859,0.576565656565657,0.584545454545455,0.592525252525253,0.600505050505051,0.608484848484849,0.616464646464647,0.624444444444445,0.632424242424243,0.640404040404041,0.648383838383839,0.656363636363636,0.664343434343434,0.672323232323232,0.68030303030303,0.688282828282828,0.696262626262626,0.704242424242424,0.712222222222222,0.72020202020202,0.728181818181818,0.736161616161616,0.744141414141414,0.752121212121212,0.76010101010101,0.768080808080808,0.776060606060606,0.784040404040404,0.792020202020202,0.8],"y":[0.917444364680546,0.936826992103374,0.946877243359655,0.954773869346734,0.95908111988514,0.961234745154343,0.964106245513281,0.964824120603015,0.965541995692749,0.966259870782484,0.967695620961953,0.968413496051687,0.969849246231156,0.97056712132089,0.97056712132089,0.97056712132089,0.97056712132089,0.971284996410625,0.971284996410625,0.97056712132089,0.97056712132089,0.97056712132089,0.97056712132089,0.97056712132089,0.971284996410625,0.971284996410625,0.971284996410625,0.971284996410625,0.971284996410625,0.971284996410625,0.971284996410625,0.97056712132089,0.971284996410625,0.972002871500359,0.972720746590093,0.972002871500359,0.972720746590093,0.972720746590093,0.972720746590093,0.972720746590093,0.973438621679828,0.973438621679828,0.973438621679828,0.973438621679828,0.973438621679828,0.973438621679828,0.973438621679828,0.973438621679828,0.972720746590093,0.972720746590093,0.972720746590093,0.972720746590093,0.973438621679828,0.973438621679828,0.974156496769562,0.974874371859296,0.974874371859296,0.976310122038765,0.976310122038765,0.976310122038765,0.975592246949031,0.975592246949031,0.975592246949031,0.975592246949031,0.975592246949031,0.975592246949031,0.975592246949031,0.975592246949031,0.975592246949031,0.975592246949031,0.975592246949031,0.975592246949031,0.9770279971285,0.9770279971285,0.9770279971285,0.9770279971285,0.9770279971285,0.9770279971285,0.978463747307968,0.978463747307968,0.978463747307968,0.978463747307968,0.978463747307968,0.978463747307968,0.978463747307968,0.978463747307968,0.977745872218234,0.977745872218234,0.977745872218234,0.977745872218234,0.977745872218234,0.977745872218234,0.976310122038765,0.975592246949031,0.975592246949031,0.975592246949031,0.975592246949031,0.975592246949031,0.975592246949031,0.975592246949031],"text":["Cutoff: 0.01000000<br />value: 0.9174444<br />performa: Accuracy","Cutoff: 0.01797980<br />value: 0.9368270<br />performa: Accuracy","Cutoff: 0.02595960<br />value: 0.9468772<br />performa: Accuracy","Cutoff: 0.03393939<br />value: 0.9547739<br />performa: Accuracy","Cutoff: 0.04191919<br />value: 0.9590811<br />performa: Accuracy","Cutoff: 0.04989899<br />value: 0.9612347<br />performa: Accuracy","Cutoff: 0.05787879<br />value: 0.9641062<br />performa: Accuracy","Cutoff: 0.06585859<br />value: 0.9648241<br />performa: Accuracy","Cutoff: 0.07383838<br />value: 0.9655420<br />performa: Accuracy","Cutoff: 0.08181818<br />value: 0.9662599<br />performa: Accuracy","Cutoff: 0.08979798<br />value: 0.9676956<br />performa: Accuracy","Cutoff: 0.09777778<br />value: 0.9684135<br />performa: Accuracy","Cutoff: 0.10575758<br />value: 0.9698492<br />performa: Accuracy","Cutoff: 0.11373737<br />value: 0.9705671<br />performa: Accuracy","Cutoff: 0.12171717<br />value: 0.9705671<br />performa: Accuracy","Cutoff: 0.12969697<br />value: 0.9705671<br />performa: Accuracy","Cutoff: 0.13767677<br />value: 0.9705671<br />performa: Accuracy","Cutoff: 0.14565657<br />value: 0.9712850<br />performa: Accuracy","Cutoff: 0.15363636<br />value: 0.9712850<br />performa: Accuracy","Cutoff: 0.16161616<br />value: 0.9705671<br />performa: Accuracy","Cutoff: 0.16959596<br />value: 0.9705671<br />performa: Accuracy","Cutoff: 0.17757576<br />value: 0.9705671<br />performa: Accuracy","Cutoff: 0.18555556<br />value: 0.9705671<br />performa: Accuracy","Cutoff: 0.19353535<br />value: 0.9705671<br />performa: Accuracy","Cutoff: 0.20151515<br />value: 0.9712850<br />performa: Accuracy","Cutoff: 0.20949495<br />value: 0.9712850<br />performa: Accuracy","Cutoff: 0.21747475<br />value: 0.9712850<br />performa: Accuracy","Cutoff: 0.22545455<br />value: 0.9712850<br />performa: Accuracy","Cutoff: 0.23343434<br />value: 0.9712850<br />performa: Accuracy","Cutoff: 0.24141414<br />value: 0.9712850<br />performa: Accuracy","Cutoff: 0.24939394<br />value: 0.9712850<br />performa: Accuracy","Cutoff: 0.25737374<br />value: 0.9705671<br />performa: Accuracy","Cutoff: 0.26535354<br />value: 0.9712850<br />performa: Accuracy","Cutoff: 0.27333333<br />value: 0.9720029<br />performa: Accuracy","Cutoff: 0.28131313<br />value: 0.9727207<br />performa: Accuracy","Cutoff: 0.28929293<br />value: 0.9720029<br />performa: Accuracy","Cutoff: 0.29727273<br />value: 0.9727207<br />performa: Accuracy","Cutoff: 0.30525253<br />value: 0.9727207<br />performa: Accuracy","Cutoff: 0.31323232<br />value: 0.9727207<br />performa: Accuracy","Cutoff: 0.32121212<br />value: 0.9727207<br />performa: Accuracy","Cutoff: 0.32919192<br />value: 0.9734386<br />performa: Accuracy","Cutoff: 0.33717172<br />value: 0.9734386<br />performa: Accuracy","Cutoff: 0.34515152<br />value: 0.9734386<br />performa: Accuracy","Cutoff: 0.35313131<br />value: 0.9734386<br />performa: Accuracy","Cutoff: 0.36111111<br />value: 0.9734386<br />performa: Accuracy","Cutoff: 0.36909091<br />value: 0.9734386<br />performa: Accuracy","Cutoff: 0.37707071<br />value: 0.9734386<br />performa: Accuracy","Cutoff: 0.38505051<br />value: 0.9734386<br />performa: Accuracy","Cutoff: 0.39303030<br />value: 0.9727207<br />performa: Accuracy","Cutoff: 0.40101010<br />value: 0.9727207<br />performa: Accuracy","Cutoff: 0.40898990<br />value: 0.9727207<br />performa: Accuracy","Cutoff: 0.41696970<br />value: 0.9727207<br />performa: Accuracy","Cutoff: 0.42494949<br />value: 0.9734386<br />performa: Accuracy","Cutoff: 0.43292929<br />value: 0.9734386<br />performa: Accuracy","Cutoff: 0.44090909<br />value: 0.9741565<br />performa: Accuracy","Cutoff: 0.44888889<br />value: 0.9748744<br />performa: Accuracy","Cutoff: 0.45686869<br />value: 0.9748744<br />performa: Accuracy","Cutoff: 0.46484848<br />value: 0.9763101<br />performa: Accuracy","Cutoff: 0.47282828<br />value: 0.9763101<br />performa: Accuracy","Cutoff: 0.48080808<br />value: 0.9763101<br />performa: Accuracy","Cutoff: 0.48878788<br />value: 0.9755922<br />performa: Accuracy","Cutoff: 0.49676768<br />value: 0.9755922<br />performa: Accuracy","Cutoff: 0.50474747<br />value: 0.9755922<br />performa: Accuracy","Cutoff: 0.51272727<br />value: 0.9755922<br />performa: Accuracy","Cutoff: 0.52070707<br />value: 0.9755922<br />performa: Accuracy","Cutoff: 0.52868687<br />value: 0.9755922<br />performa: Accuracy","Cutoff: 0.53666667<br />value: 0.9755922<br />performa: Accuracy","Cutoff: 0.54464646<br />value: 0.9755922<br />performa: Accuracy","Cutoff: 0.55262626<br />value: 0.9755922<br />performa: Accuracy","Cutoff: 0.56060606<br />value: 0.9755922<br />performa: Accuracy","Cutoff: 0.56858586<br />value: 0.9755922<br />performa: Accuracy","Cutoff: 0.57656566<br />value: 0.9755922<br />performa: Accuracy","Cutoff: 0.58454545<br />value: 0.9770280<br />performa: Accuracy","Cutoff: 0.59252525<br />value: 0.9770280<br />performa: Accuracy","Cutoff: 0.60050505<br />value: 0.9770280<br />performa: Accuracy","Cutoff: 0.60848485<br />value: 0.9770280<br />performa: Accuracy","Cutoff: 0.61646465<br />value: 0.9770280<br />performa: Accuracy","Cutoff: 0.62444444<br />value: 0.9770280<br />performa: Accuracy","Cutoff: 0.63242424<br />value: 0.9784637<br />performa: Accuracy","Cutoff: 0.64040404<br />value: 0.9784637<br />performa: Accuracy","Cutoff: 0.64838384<br />value: 0.9784637<br />performa: Accuracy","Cutoff: 0.65636364<br />value: 0.9784637<br />performa: Accuracy","Cutoff: 0.66434343<br />value: 0.9784637<br />performa: Accuracy","Cutoff: 0.67232323<br />value: 0.9784637<br />performa: Accuracy","Cutoff: 0.68030303<br />value: 0.9784637<br />performa: Accuracy","Cutoff: 0.68828283<br />value: 0.9784637<br />performa: Accuracy","Cutoff: 0.69626263<br />value: 0.9777459<br />performa: Accuracy","Cutoff: 0.70424242<br />value: 0.9777459<br />performa: Accuracy","Cutoff: 0.71222222<br />value: 0.9777459<br />performa: Accuracy","Cutoff: 0.72020202<br />value: 0.9777459<br />performa: Accuracy","Cutoff: 0.72818182<br />value: 0.9777459<br />performa: Accuracy","Cutoff: 0.73616162<br />value: 0.9777459<br />performa: Accuracy","Cutoff: 0.74414141<br />value: 0.9763101<br />performa: Accuracy","Cutoff: 0.75212121<br />value: 0.9755922<br />performa: Accuracy","Cutoff: 0.76010101<br />value: 0.9755922<br />performa: Accuracy","Cutoff: 0.76808081<br />value: 0.9755922<br />performa: Accuracy","Cutoff: 0.77606061<br />value: 0.9755922<br />performa: Accuracy","Cutoff: 0.78404040<br />value: 0.9755922<br />performa: Accuracy","Cutoff: 0.79202020<br />value: 0.9755922<br />performa: Accuracy","Cutoff: 0.80000000<br />value: 0.9755922<br />performa: Accuracy"],"type":"scatter","mode":"lines","line":{"width":5.66929133858268,"color":"rgba(178,34,34,1)","dash":"solid"},"hoveron":"points","name":"Accuracy","legendgroup":"Accuracy","showlegend":true,"xaxis":"x","yaxis":"y","hoverinfo":"text","frame":null},{"x":[0.01,0.017979797979798,0.025959595959596,0.0339393939393939,0.0419191919191919,0.0498989898989899,0.0578787878787879,0.0658585858585859,0.0738383838383838,0.0818181818181818,0.0897979797979798,0.0977777777777778,0.105757575757576,0.113737373737374,0.121717171717172,0.12969696969697,0.137676767676768,0.145656565656566,0.153636363636364,0.161616161616162,0.16959595959596,0.177575757575758,0.185555555555556,0.193535353535354,0.201515151515152,0.20949494949495,0.217474747474748,0.225454545454545,0.233434343434343,0.241414141414141,0.249393939393939,0.257373737373737,0.265353535353535,0.273333333333333,0.281313131313131,0.289292929292929,0.297272727272727,0.305252525252525,0.313232323232323,0.321212121212121,0.329191919191919,0.337171717171717,0.345151515151515,0.353131313131313,0.361111111111111,0.369090909090909,0.377070707070707,0.385050505050505,0.393030303030303,0.401010101010101,0.408989898989899,0.416969696969697,0.424949494949495,0.432929292929293,0.440909090909091,0.448888888888889,0.456868686868687,0.464848484848485,0.472828282828283,0.480808080808081,0.488787878787879,0.496767676767677,0.504747474747475,0.512727272727273,0.520707070707071,0.528686868686869,0.536666666666667,0.544646464646465,0.552626262626263,0.560606060606061,0.568585858585859,0.576565656565657,0.584545454545455,0.592525252525253,0.600505050505051,0.608484848484849,0.616464646464647,0.624444444444445,0.632424242424243,0.640404040404041,0.648383838383839,0.656363636363636,0.664343434343434,0.672323232323232,0.68030303030303,0.688282828282828,0.696262626262626,0.704242424242424,0.712222222222222,0.72020202020202,0.728181818181818,0.736161616161616,0.744141414141414,0.752121212121212,0.76010101010101,0.768080808080808,0.776060606060606,0.784040404040404,0.792020202020202,0.8],"y":[0.615384615384615,0.688311688311688,0.734883720930232,0.774509803921569,0.797979797979798,0.81025641025641,0.827225130890052,0.831578947368421,0.835978835978836,0.840425531914894,0.853260869565217,0.85792349726776,0.867403314917127,0.876404494382023,0.876404494382023,0.880681818181818,0.885057471264368,0.894736842105263,0.894736842105263,0.894117647058824,0.894117647058824,0.894117647058824,0.894117647058824,0.894117647058824,0.899408284023668,0.899408284023668,0.899408284023668,0.899408284023668,0.899408284023668,0.899408284023668,0.899408284023668,0.898809523809524,0.904191616766467,0.909638554216867,0.915151515151515,0.914634146341463,0.920245398773006,0.920245398773006,0.920245398773006,0.920245398773006,0.925925925925926,0.925925925925926,0.925925925925926,0.925925925925926,0.925925925925926,0.925925925925926,0.925925925925926,0.925925925925926,0.925465838509317,0.925465838509317,0.925465838509317,0.925465838509317,0.93125,0.93125,0.937106918238994,0.943037974683544,0.943037974683544,0.955128205128205,0.955128205128205,0.955128205128205,0.954838709677419,0.954838709677419,0.954838709677419,0.954838709677419,0.954838709677419,0.954838709677419,0.954838709677419,0.954838709677419,0.954838709677419,0.954838709677419,0.954838709677419,0.954838709677419,0.967320261437908,0.967320261437908,0.967320261437908,0.967320261437908,0.967320261437908,0.967320261437908,0.980132450331125,0.980132450331125,0.980132450331125,0.980132450331125,0.980132450331125,0.980132450331125,0.980132450331125,0.980132450331125,0.98,0.98,0.98,0.98,0.98,0.98,0.979729729729729,0.979591836734693,0.979591836734693,0.979591836734693,0.979591836734693,0.979591836734693,0.979591836734693,0.979591836734693],"text":["Cutoff: 0.01000000<br />value: 0.6153846<br />performa: Precision","Cutoff: 0.01797980<br />value: 0.6883117<br />performa: Precision","Cutoff: 0.02595960<br />value: 0.7348837<br />performa: Precision","Cutoff: 0.03393939<br />value: 0.7745098<br />performa: Precision","Cutoff: 0.04191919<br />value: 0.7979798<br />performa: Precision","Cutoff: 0.04989899<br />value: 0.8102564<br />performa: Precision","Cutoff: 0.05787879<br />value: 0.8272251<br />performa: Precision","Cutoff: 0.06585859<br />value: 0.8315789<br />performa: Precision","Cutoff: 0.07383838<br />value: 0.8359788<br />performa: Precision","Cutoff: 0.08181818<br />value: 0.8404255<br />performa: Precision","Cutoff: 0.08979798<br />value: 0.8532609<br />performa: Precision","Cutoff: 0.09777778<br />value: 0.8579235<br />performa: Precision","Cutoff: 0.10575758<br />value: 0.8674033<br />performa: Precision","Cutoff: 0.11373737<br />value: 0.8764045<br />performa: Precision","Cutoff: 0.12171717<br />value: 0.8764045<br />performa: Precision","Cutoff: 0.12969697<br />value: 0.8806818<br />performa: Precision","Cutoff: 0.13767677<br />value: 0.8850575<br />performa: Precision","Cutoff: 0.14565657<br />value: 0.8947368<br />performa: Precision","Cutoff: 0.15363636<br />value: 0.8947368<br />performa: Precision","Cutoff: 0.16161616<br />value: 0.8941176<br />performa: Precision","Cutoff: 0.16959596<br />value: 0.8941176<br />performa: Precision","Cutoff: 0.17757576<br />value: 0.8941176<br />performa: Precision","Cutoff: 0.18555556<br />value: 0.8941176<br />performa: Precision","Cutoff: 0.19353535<br />value: 0.8941176<br />performa: Precision","Cutoff: 0.20151515<br />value: 0.8994083<br />performa: Precision","Cutoff: 0.20949495<br />value: 0.8994083<br />performa: Precision","Cutoff: 0.21747475<br />value: 0.8994083<br />performa: Precision","Cutoff: 0.22545455<br />value: 0.8994083<br />performa: Precision","Cutoff: 0.23343434<br />value: 0.8994083<br />performa: Precision","Cutoff: 0.24141414<br />value: 0.8994083<br />performa: Precision","Cutoff: 0.24939394<br />value: 0.8994083<br />performa: Precision","Cutoff: 0.25737374<br />value: 0.8988095<br />performa: Precision","Cutoff: 0.26535354<br />value: 0.9041916<br />performa: Precision","Cutoff: 0.27333333<br />value: 0.9096386<br />performa: Precision","Cutoff: 0.28131313<br />value: 0.9151515<br />performa: Precision","Cutoff: 0.28929293<br />value: 0.9146341<br />performa: Precision","Cutoff: 0.29727273<br />value: 0.9202454<br />performa: Precision","Cutoff: 0.30525253<br />value: 0.9202454<br />performa: Precision","Cutoff: 0.31323232<br />value: 0.9202454<br />performa: Precision","Cutoff: 0.32121212<br />value: 0.9202454<br />performa: Precision","Cutoff: 0.32919192<br />value: 0.9259259<br />performa: Precision","Cutoff: 0.33717172<br />value: 0.9259259<br />performa: Precision","Cutoff: 0.34515152<br />value: 0.9259259<br />performa: Precision","Cutoff: 0.35313131<br />value: 0.9259259<br />performa: Precision","Cutoff: 0.36111111<br />value: 0.9259259<br />performa: Precision","Cutoff: 0.36909091<br />value: 0.9259259<br />performa: Precision","Cutoff: 0.37707071<br />value: 0.9259259<br />performa: Precision","Cutoff: 0.38505051<br />value: 0.9259259<br />performa: Precision","Cutoff: 0.39303030<br />value: 0.9254658<br />performa: Precision","Cutoff: 0.40101010<br />value: 0.9254658<br />performa: Precision","Cutoff: 0.40898990<br />value: 0.9254658<br />performa: Precision","Cutoff: 0.41696970<br />value: 0.9254658<br />performa: Precision","Cutoff: 0.42494949<br />value: 0.9312500<br />performa: Precision","Cutoff: 0.43292929<br />value: 0.9312500<br />performa: Precision","Cutoff: 0.44090909<br />value: 0.9371069<br />performa: Precision","Cutoff: 0.44888889<br />value: 0.9430380<br />performa: Precision","Cutoff: 0.45686869<br />value: 0.9430380<br />performa: Precision","Cutoff: 0.46484848<br />value: 0.9551282<br />performa: Precision","Cutoff: 0.47282828<br />value: 0.9551282<br />performa: Precision","Cutoff: 0.48080808<br />value: 0.9551282<br />performa: Precision","Cutoff: 0.48878788<br />value: 0.9548387<br />performa: Precision","Cutoff: 0.49676768<br />value: 0.9548387<br />performa: Precision","Cutoff: 0.50474747<br />value: 0.9548387<br />performa: Precision","Cutoff: 0.51272727<br />value: 0.9548387<br />performa: Precision","Cutoff: 0.52070707<br />value: 0.9548387<br />performa: Precision","Cutoff: 0.52868687<br />value: 0.9548387<br />performa: Precision","Cutoff: 0.53666667<br />value: 0.9548387<br />performa: Precision","Cutoff: 0.54464646<br />value: 0.9548387<br />performa: Precision","Cutoff: 0.55262626<br />value: 0.9548387<br />performa: Precision","Cutoff: 0.56060606<br />value: 0.9548387<br />performa: Precision","Cutoff: 0.56858586<br />value: 0.9548387<br />performa: Precision","Cutoff: 0.57656566<br />value: 0.9548387<br />performa: Precision","Cutoff: 0.58454545<br />value: 0.9673203<br />performa: Precision","Cutoff: 0.59252525<br />value: 0.9673203<br />performa: Precision","Cutoff: 0.60050505<br />value: 0.9673203<br />performa: Precision","Cutoff: 0.60848485<br />value: 0.9673203<br />performa: Precision","Cutoff: 0.61646465<br />value: 0.9673203<br />performa: Precision","Cutoff: 0.62444444<br />value: 0.9673203<br />performa: Precision","Cutoff: 0.63242424<br />value: 0.9801325<br />performa: Precision","Cutoff: 0.64040404<br />value: 0.9801325<br />performa: Precision","Cutoff: 0.64838384<br />value: 0.9801325<br />performa: Precision","Cutoff: 0.65636364<br />value: 0.9801325<br />performa: Precision","Cutoff: 0.66434343<br />value: 0.9801325<br />performa: Precision","Cutoff: 0.67232323<br />value: 0.9801325<br />performa: Precision","Cutoff: 0.68030303<br />value: 0.9801325<br />performa: Precision","Cutoff: 0.68828283<br />value: 0.9801325<br />performa: Precision","Cutoff: 0.69626263<br />value: 0.9800000<br />performa: Precision","Cutoff: 0.70424242<br />value: 0.9800000<br />performa: Precision","Cutoff: 0.71222222<br />value: 0.9800000<br />performa: Precision","Cutoff: 0.72020202<br />value: 0.9800000<br />performa: Precision","Cutoff: 0.72818182<br />value: 0.9800000<br />performa: Precision","Cutoff: 0.73616162<br />value: 0.9800000<br />performa: Precision","Cutoff: 0.74414141<br />value: 0.9797297<br />performa: Precision","Cutoff: 0.75212121<br />value: 0.9795918<br />performa: Precision","Cutoff: 0.76010101<br />value: 0.9795918<br />performa: Precision","Cutoff: 0.76808081<br />value: 0.9795918<br />performa: Precision","Cutoff: 0.77606061<br />value: 0.9795918<br />performa: Precision","Cutoff: 0.78404040<br />value: 0.9795918<br />performa: Precision","Cutoff: 0.79202020<br />value: 0.9795918<br />performa: Precision","Cutoff: 0.80000000<br />value: 0.9795918<br />performa: Precision"],"type":"scatter","mode":"lines","line":{"width":5.66929133858268,"color":"rgba(16,78,139,1)","dash":"solid"},"hoveron":"points","name":"Precision","legendgroup":"Precision","showlegend":true,"xaxis":"x","yaxis":"y","hoverinfo":"text","frame":null},{"x":[0.01,0.017979797979798,0.025959595959596,0.0339393939393939,0.0419191919191919,0.0498989898989899,0.0578787878787879,0.0658585858585859,0.0738383838383838,0.0818181818181818,0.0897979797979798,0.0977777777777778,0.105757575757576,0.113737373737374,0.121717171717172,0.12969696969697,0.137676767676768,0.145656565656566,0.153636363636364,0.161616161616162,0.16959595959596,0.177575757575758,0.185555555555556,0.193535353535354,0.201515151515152,0.20949494949495,0.217474747474748,0.225454545454545,0.233434343434343,0.241414141414141,0.249393939393939,0.257373737373737,0.265353535353535,0.273333333333333,0.281313131313131,0.289292929292929,0.297272727272727,0.305252525252525,0.313232323232323,0.321212121212121,0.329191919191919,0.337171717171717,0.345151515151515,0.353131313131313,0.361111111111111,0.369090909090909,0.377070707070707,0.385050505050505,0.393030303030303,0.401010101010101,0.408989898989899,0.416969696969697,0.424949494949495,0.432929292929293,0.440909090909091,0.448888888888889,0.456868686868687,0.464848484848485,0.472828282828283,0.480808080808081,0.488787878787879,0.496767676767677,0.504747474747475,0.512727272727273,0.520707070707071,0.528686868686869,0.536666666666667,0.544646464646465,0.552626262626263,0.560606060606061,0.568585858585859,0.576565656565657,0.584545454545455,0.592525252525253,0.600505050505051,0.608484848484849,0.616464646464647,0.624444444444445,0.632424242424243,0.640404040404041,0.648383838383839,0.656363636363636,0.664343434343434,0.672323232323232,0.68030303030303,0.688282828282828,0.696262626262626,0.704242424242424,0.712222222222222,0.72020202020202,0.728181818181818,0.736161616161616,0.744141414141414,0.752121212121212,0.76010101010101,0.768080808080808,0.776060606060606,0.784040404040404,0.792020202020202,0.8],"y":[0.914285714285714,0.908571428571429,0.902857142857143,0.902857142857143,0.902857142857143,0.902857142857143,0.902857142857143,0.902857142857143,0.902857142857143,0.902857142857143,0.897142857142857,0.897142857142857,0.897142857142857,0.891428571428571,0.891428571428571,0.885714285714286,0.88,0.874285714285714,0.874285714285714,0.868571428571429,0.868571428571429,0.868571428571429,0.868571428571429,0.868571428571429,0.868571428571429,0.868571428571429,0.868571428571429,0.868571428571429,0.868571428571429,0.868571428571429,0.868571428571429,0.862857142857143,0.862857142857143,0.862857142857143,0.862857142857143,0.857142857142857,0.857142857142857,0.857142857142857,0.857142857142857,0.857142857142857,0.857142857142857,0.857142857142857,0.857142857142857,0.857142857142857,0.857142857142857,0.857142857142857,0.857142857142857,0.857142857142857,0.851428571428571,0.851428571428571,0.851428571428571,0.851428571428571,0.851428571428571,0.851428571428571,0.851428571428571,0.851428571428571,0.851428571428571,0.851428571428571,0.851428571428571,0.851428571428571,0.845714285714286,0.845714285714286,0.845714285714286,0.845714285714286,0.845714285714286,0.845714285714286,0.845714285714286,0.845714285714286,0.845714285714286,0.845714285714286,0.845714285714286,0.845714285714286,0.845714285714286,0.845714285714286,0.845714285714286,0.845714285714286,0.845714285714286,0.845714285714286,0.845714285714286,0.845714285714286,0.845714285714286,0.845714285714286,0.845714285714286,0.845714285714286,0.845714285714286,0.845714285714286,0.84,0.84,0.84,0.84,0.84,0.84,0.828571428571429,0.822857142857143,0.822857142857143,0.822857142857143,0.822857142857143,0.822857142857143,0.822857142857143,0.822857142857143],"text":["Cutoff: 0.01000000<br />value: 0.9142857<br />performa: Recall","Cutoff: 0.01797980<br />value: 0.9085714<br />performa: Recall","Cutoff: 0.02595960<br />value: 0.9028571<br />performa: Recall","Cutoff: 0.03393939<br />value: 0.9028571<br />performa: Recall","Cutoff: 0.04191919<br />value: 0.9028571<br />performa: Recall","Cutoff: 0.04989899<br />value: 0.9028571<br />performa: Recall","Cutoff: 0.05787879<br />value: 0.9028571<br />performa: Recall","Cutoff: 0.06585859<br />value: 0.9028571<br />performa: Recall","Cutoff: 0.07383838<br />value: 0.9028571<br />performa: Recall","Cutoff: 0.08181818<br />value: 0.9028571<br />performa: Recall","Cutoff: 0.08979798<br />value: 0.8971429<br />performa: Recall","Cutoff: 0.09777778<br />value: 0.8971429<br />performa: Recall","Cutoff: 0.10575758<br />value: 0.8971429<br />performa: Recall","Cutoff: 0.11373737<br />value: 0.8914286<br />performa: Recall","Cutoff: 0.12171717<br />value: 0.8914286<br />performa: Recall","Cutoff: 0.12969697<br />value: 0.8857143<br />performa: Recall","Cutoff: 0.13767677<br />value: 0.8800000<br />performa: Recall","Cutoff: 0.14565657<br />value: 0.8742857<br />performa: Recall","Cutoff: 0.15363636<br />value: 0.8742857<br />performa: Recall","Cutoff: 0.16161616<br />value: 0.8685714<br />performa: Recall","Cutoff: 0.16959596<br />value: 0.8685714<br />performa: Recall","Cutoff: 0.17757576<br />value: 0.8685714<br />performa: Recall","Cutoff: 0.18555556<br />value: 0.8685714<br />performa: Recall","Cutoff: 0.19353535<br />value: 0.8685714<br />performa: Recall","Cutoff: 0.20151515<br />value: 0.8685714<br />performa: Recall","Cutoff: 0.20949495<br />value: 0.8685714<br />performa: Recall","Cutoff: 0.21747475<br />value: 0.8685714<br />performa: Recall","Cutoff: 0.22545455<br />value: 0.8685714<br />performa: Recall","Cutoff: 0.23343434<br />value: 0.8685714<br />performa: Recall","Cutoff: 0.24141414<br />value: 0.8685714<br />performa: Recall","Cutoff: 0.24939394<br />value: 0.8685714<br />performa: Recall","Cutoff: 0.25737374<br />value: 0.8628571<br />performa: Recall","Cutoff: 0.26535354<br />value: 0.8628571<br />performa: Recall","Cutoff: 0.27333333<br />value: 0.8628571<br />performa: Recall","Cutoff: 0.28131313<br />value: 0.8628571<br />performa: Recall","Cutoff: 0.28929293<br />value: 0.8571429<br />performa: Recall","Cutoff: 0.29727273<br />value: 0.8571429<br />performa: Recall","Cutoff: 0.30525253<br />value: 0.8571429<br />performa: Recall","Cutoff: 0.31323232<br />value: 0.8571429<br />performa: Recall","Cutoff: 0.32121212<br />value: 0.8571429<br />performa: Recall","Cutoff: 0.32919192<br />value: 0.8571429<br />performa: Recall","Cutoff: 0.33717172<br />value: 0.8571429<br />performa: Recall","Cutoff: 0.34515152<br />value: 0.8571429<br />performa: Recall","Cutoff: 0.35313131<br />value: 0.8571429<br />performa: Recall","Cutoff: 0.36111111<br />value: 0.8571429<br />performa: Recall","Cutoff: 0.36909091<br />value: 0.8571429<br />performa: Recall","Cutoff: 0.37707071<br />value: 0.8571429<br />performa: Recall","Cutoff: 0.38505051<br />value: 0.8571429<br />performa: Recall","Cutoff: 0.39303030<br />value: 0.8514286<br />performa: Recall","Cutoff: 0.40101010<br />value: 0.8514286<br />performa: Recall","Cutoff: 0.40898990<br />value: 0.8514286<br />performa: Recall","Cutoff: 0.41696970<br />value: 0.8514286<br />performa: Recall","Cutoff: 0.42494949<br />value: 0.8514286<br />performa: Recall","Cutoff: 0.43292929<br />value: 0.8514286<br />performa: Recall","Cutoff: 0.44090909<br />value: 0.8514286<br />performa: Recall","Cutoff: 0.44888889<br />value: 0.8514286<br />performa: Recall","Cutoff: 0.45686869<br />value: 0.8514286<br />performa: Recall","Cutoff: 0.46484848<br />value: 0.8514286<br />performa: Recall","Cutoff: 0.47282828<br />value: 0.8514286<br />performa: Recall","Cutoff: 0.48080808<br />value: 0.8514286<br />performa: Recall","Cutoff: 0.48878788<br />value: 0.8457143<br />performa: Recall","Cutoff: 0.49676768<br />value: 0.8457143<br />performa: Recall","Cutoff: 0.50474747<br />value: 0.8457143<br />performa: Recall","Cutoff: 0.51272727<br />value: 0.8457143<br />performa: Recall","Cutoff: 0.52070707<br />value: 0.8457143<br />performa: Recall","Cutoff: 0.52868687<br />value: 0.8457143<br />performa: Recall","Cutoff: 0.53666667<br />value: 0.8457143<br />performa: Recall","Cutoff: 0.54464646<br />value: 0.8457143<br />performa: Recall","Cutoff: 0.55262626<br />value: 0.8457143<br />performa: Recall","Cutoff: 0.56060606<br />value: 0.8457143<br />performa: Recall","Cutoff: 0.56858586<br />value: 0.8457143<br />performa: Recall","Cutoff: 0.57656566<br />value: 0.8457143<br />performa: Recall","Cutoff: 0.58454545<br />value: 0.8457143<br />performa: Recall","Cutoff: 0.59252525<br />value: 0.8457143<br />performa: Recall","Cutoff: 0.60050505<br />value: 0.8457143<br />performa: Recall","Cutoff: 0.60848485<br />value: 0.8457143<br />performa: Recall","Cutoff: 0.61646465<br />value: 0.8457143<br />performa: Recall","Cutoff: 0.62444444<br />value: 0.8457143<br />performa: Recall","Cutoff: 0.63242424<br />value: 0.8457143<br />performa: Recall","Cutoff: 0.64040404<br />value: 0.8457143<br />performa: Recall","Cutoff: 0.64838384<br />value: 0.8457143<br />performa: Recall","Cutoff: 0.65636364<br />value: 0.8457143<br />performa: Recall","Cutoff: 0.66434343<br />value: 0.8457143<br />performa: Recall","Cutoff: 0.67232323<br />value: 0.8457143<br />performa: Recall","Cutoff: 0.68030303<br />value: 0.8457143<br />performa: Recall","Cutoff: 0.68828283<br />value: 0.8457143<br />performa: Recall","Cutoff: 0.69626263<br />value: 0.8400000<br />performa: Recall","Cutoff: 0.70424242<br />value: 0.8400000<br />performa: Recall","Cutoff: 0.71222222<br />value: 0.8400000<br />performa: Recall","Cutoff: 0.72020202<br />value: 0.8400000<br />performa: Recall","Cutoff: 0.72818182<br />value: 0.8400000<br />performa: Recall","Cutoff: 0.73616162<br />value: 0.8400000<br />performa: Recall","Cutoff: 0.74414141<br />value: 0.8285714<br />performa: Recall","Cutoff: 0.75212121<br />value: 0.8228571<br />performa: Recall","Cutoff: 0.76010101<br />value: 0.8228571<br />performa: Recall","Cutoff: 0.76808081<br />value: 0.8228571<br />performa: Recall","Cutoff: 0.77606061<br />value: 0.8228571<br />performa: Recall","Cutoff: 0.78404040<br />value: 0.8228571<br />performa: Recall","Cutoff: 0.79202020<br />value: 0.8228571<br />performa: Recall","Cutoff: 0.80000000<br />value: 0.8228571<br />performa: Recall"],"type":"scatter","mode":"lines","line":{"width":5.66929133858268,"color":"rgba(0,100,0,1)","dash":"solid"},"hoveron":"points","name":"Recall","legendgroup":"Recall","showlegend":true,"xaxis":"x","yaxis":"y","hoverinfo":"text","frame":null},{"x":[0.01,0.017979797979798,0.025959595959596,0.0339393939393939,0.0419191919191919,0.0498989898989899,0.0578787878787879,0.0658585858585859,0.0738383838383838,0.0818181818181818,0.0897979797979798,0.0977777777777778,0.105757575757576,0.113737373737374,0.121717171717172,0.12969696969697,0.137676767676768,0.145656565656566,0.153636363636364,0.161616161616162,0.16959595959596,0.177575757575758,0.185555555555556,0.193535353535354,0.201515151515152,0.20949494949495,0.217474747474748,0.225454545454545,0.233434343434343,0.241414141414141,0.249393939393939,0.257373737373737,0.265353535353535,0.273333333333333,0.281313131313131,0.289292929292929,0.297272727272727,0.305252525252525,0.313232323232323,0.321212121212121,0.329191919191919,0.337171717171717,0.345151515151515,0.353131313131313,0.361111111111111,0.369090909090909,0.377070707070707,0.385050505050505,0.393030303030303,0.401010101010101,0.408989898989899,0.416969696969697,0.424949494949495,0.432929292929293,0.440909090909091,0.448888888888889,0.456868686868687,0.464848484848485,0.472828282828283,0.480808080808081,0.488787878787879,0.496767676767677,0.504747474747475,0.512727272727273,0.520707070707071,0.528686868686869,0.536666666666667,0.544646464646465,0.552626262626263,0.560606060606061,0.568585858585859,0.576565656565657,0.584545454545455,0.592525252525253,0.600505050505051,0.608484848484849,0.616464646464647,0.624444444444445,0.632424242424243,0.640404040404041,0.648383838383839,0.656363636363636,0.664343434343434,0.672323232323232,0.68030303030303,0.688282828282828,0.696262626262626,0.704242424242424,0.712222222222222,0.72020202020202,0.728181818181818,0.736161616161616,0.744141414141414,0.752121212121212,0.76010101010101,0.768080808080808,0.776060606060606,0.784040404040404,0.792020202020202,0.8],"y":[0.917898193760263,0.940886699507389,0.95320197044335,0.962233169129721,0.967159277504105,0.969622331691297,0.972906403940887,0.973727422003284,0.974548440065681,0.975369458128079,0.977832512315271,0.978653530377668,0.980295566502463,0.981937602627258,0.981937602627258,0.982758620689655,0.983579638752053,0.985221674876847,0.985221674876847,0.985221674876847,0.985221674876847,0.985221674876847,0.985221674876847,0.985221674876847,0.986042692939245,0.986042692939245,0.986042692939245,0.986042692939245,0.986042692939245,0.986042692939245,0.986042692939245,0.986042692939245,0.986863711001642,0.987684729064039,0.988505747126437,0.988505747126437,0.989326765188834,0.989326765188834,0.989326765188834,0.989326765188834,0.990147783251232,0.990147783251232,0.990147783251232,0.990147783251232,0.990147783251232,0.990147783251232,0.990147783251232,0.990147783251232,0.990147783251232,0.990147783251232,0.990147783251232,0.990147783251232,0.990968801313629,0.990968801313629,0.991789819376026,0.992610837438424,0.992610837438424,0.994252873563218,0.994252873563218,0.994252873563218,0.994252873563218,0.994252873563218,0.994252873563218,0.994252873563218,0.994252873563218,0.994252873563218,0.994252873563218,0.994252873563218,0.994252873563218,0.994252873563218,0.994252873563218,0.994252873563218,0.995894909688013,0.995894909688013,0.995894909688013,0.995894909688013,0.995894909688013,0.995894909688013,0.997536945812808,0.997536945812808,0.997536945812808,0.997536945812808,0.997536945812808,0.997536945812808,0.997536945812808,0.997536945812808,0.997536945812808,0.997536945812808,0.997536945812808,0.997536945812808,0.997536945812808,0.997536945812808,0.997536945812808,0.997536945812808,0.997536945812808,0.997536945812808,0.997536945812808,0.997536945812808,0.997536945812808,0.997536945812808],"text":["Cutoff: 0.01000000<br />value: 0.9178982<br />performa: Specificity","Cutoff: 0.01797980<br />value: 0.9408867<br />performa: Specificity","Cutoff: 0.02595960<br />value: 0.9532020<br />performa: Specificity","Cutoff: 0.03393939<br />value: 0.9622332<br />performa: Specificity","Cutoff: 0.04191919<br />value: 0.9671593<br />performa: Specificity","Cutoff: 0.04989899<br />value: 0.9696223<br />performa: Specificity","Cutoff: 0.05787879<br />value: 0.9729064<br />performa: Specificity","Cutoff: 0.06585859<br />value: 0.9737274<br />performa: Specificity","Cutoff: 0.07383838<br />value: 0.9745484<br />performa: Specificity","Cutoff: 0.08181818<br />value: 0.9753695<br />performa: Specificity","Cutoff: 0.08979798<br />value: 0.9778325<br />performa: Specificity","Cutoff: 0.09777778<br />value: 0.9786535<br />performa: Specificity","Cutoff: 0.10575758<br />value: 0.9802956<br />performa: Specificity","Cutoff: 0.11373737<br />value: 0.9819376<br />performa: Specificity","Cutoff: 0.12171717<br />value: 0.9819376<br />performa: Specificity","Cutoff: 0.12969697<br />value: 0.9827586<br />performa: Specificity","Cutoff: 0.13767677<br />value: 0.9835796<br />performa: Specificity","Cutoff: 0.14565657<br />value: 0.9852217<br />performa: Specificity","Cutoff: 0.15363636<br />value: 0.9852217<br />performa: Specificity","Cutoff: 0.16161616<br />value: 0.9852217<br />performa: Specificity","Cutoff: 0.16959596<br />value: 0.9852217<br />performa: Specificity","Cutoff: 0.17757576<br />value: 0.9852217<br />performa: Specificity","Cutoff: 0.18555556<br />value: 0.9852217<br />performa: Specificity","Cutoff: 0.19353535<br />value: 0.9852217<br />performa: Specificity","Cutoff: 0.20151515<br />value: 0.9860427<br />performa: Specificity","Cutoff: 0.20949495<br />value: 0.9860427<br />performa: Specificity","Cutoff: 0.21747475<br />value: 0.9860427<br />performa: Specificity","Cutoff: 0.22545455<br />value: 0.9860427<br />performa: Specificity","Cutoff: 0.23343434<br />value: 0.9860427<br />performa: Specificity","Cutoff: 0.24141414<br />value: 0.9860427<br />performa: Specificity","Cutoff: 0.24939394<br />value: 0.9860427<br />performa: Specificity","Cutoff: 0.25737374<br />value: 0.9860427<br />performa: Specificity","Cutoff: 0.26535354<br />value: 0.9868637<br />performa: Specificity","Cutoff: 0.27333333<br />value: 0.9876847<br />performa: Specificity","Cutoff: 0.28131313<br />value: 0.9885057<br />performa: Specificity","Cutoff: 0.28929293<br />value: 0.9885057<br />performa: Specificity","Cutoff: 0.29727273<br />value: 0.9893268<br />performa: Specificity","Cutoff: 0.30525253<br />value: 0.9893268<br />performa: Specificity","Cutoff: 0.31323232<br />value: 0.9893268<br />performa: Specificity","Cutoff: 0.32121212<br />value: 0.9893268<br />performa: Specificity","Cutoff: 0.32919192<br />value: 0.9901478<br />performa: Specificity","Cutoff: 0.33717172<br />value: 0.9901478<br />performa: Specificity","Cutoff: 0.34515152<br />value: 0.9901478<br />performa: Specificity","Cutoff: 0.35313131<br />value: 0.9901478<br />performa: Specificity","Cutoff: 0.36111111<br />value: 0.9901478<br />performa: Specificity","Cutoff: 0.36909091<br />value: 0.9901478<br />performa: Specificity","Cutoff: 0.37707071<br />value: 0.9901478<br />performa: Specificity","Cutoff: 0.38505051<br />value: 0.9901478<br />performa: Specificity","Cutoff: 0.39303030<br />value: 0.9901478<br />performa: Specificity","Cutoff: 0.40101010<br />value: 0.9901478<br />performa: Specificity","Cutoff: 0.40898990<br />value: 0.9901478<br />performa: Specificity","Cutoff: 0.41696970<br />value: 0.9901478<br />performa: Specificity","Cutoff: 0.42494949<br />value: 0.9909688<br />performa: Specificity","Cutoff: 0.43292929<br />value: 0.9909688<br />performa: Specificity","Cutoff: 0.44090909<br />value: 0.9917898<br />performa: Specificity","Cutoff: 0.44888889<br />value: 0.9926108<br />performa: Specificity","Cutoff: 0.45686869<br />value: 0.9926108<br />performa: Specificity","Cutoff: 0.46484848<br />value: 0.9942529<br />performa: Specificity","Cutoff: 0.47282828<br />value: 0.9942529<br />performa: Specificity","Cutoff: 0.48080808<br />value: 0.9942529<br />performa: Specificity","Cutoff: 0.48878788<br />value: 0.9942529<br />performa: Specificity","Cutoff: 0.49676768<br />value: 0.9942529<br />performa: Specificity","Cutoff: 0.50474747<br />value: 0.9942529<br />performa: Specificity","Cutoff: 0.51272727<br />value: 0.9942529<br />performa: Specificity","Cutoff: 0.52070707<br />value: 0.9942529<br />performa: Specificity","Cutoff: 0.52868687<br />value: 0.9942529<br />performa: Specificity","Cutoff: 0.53666667<br />value: 0.9942529<br />performa: Specificity","Cutoff: 0.54464646<br />value: 0.9942529<br />performa: Specificity","Cutoff: 0.55262626<br />value: 0.9942529<br />performa: Specificity","Cutoff: 0.56060606<br />value: 0.9942529<br />performa: Specificity","Cutoff: 0.56858586<br />value: 0.9942529<br />performa: Specificity","Cutoff: 0.57656566<br />value: 0.9942529<br />performa: Specificity","Cutoff: 0.58454545<br />value: 0.9958949<br />performa: Specificity","Cutoff: 0.59252525<br />value: 0.9958949<br />performa: Specificity","Cutoff: 0.60050505<br />value: 0.9958949<br />performa: Specificity","Cutoff: 0.60848485<br />value: 0.9958949<br />performa: Specificity","Cutoff: 0.61646465<br />value: 0.9958949<br />performa: Specificity","Cutoff: 0.62444444<br />value: 0.9958949<br />performa: Specificity","Cutoff: 0.63242424<br />value: 0.9975369<br />performa: Specificity","Cutoff: 0.64040404<br />value: 0.9975369<br />performa: Specificity","Cutoff: 0.64838384<br />value: 0.9975369<br />performa: Specificity","Cutoff: 0.65636364<br />value: 0.9975369<br />performa: Specificity","Cutoff: 0.66434343<br />value: 0.9975369<br />performa: Specificity","Cutoff: 0.67232323<br />value: 0.9975369<br />performa: Specificity","Cutoff: 0.68030303<br />value: 0.9975369<br />performa: Specificity","Cutoff: 0.68828283<br />value: 0.9975369<br />performa: Specificity","Cutoff: 0.69626263<br />value: 0.9975369<br />performa: Specificity","Cutoff: 0.70424242<br />value: 0.9975369<br />performa: Specificity","Cutoff: 0.71222222<br />value: 0.9975369<br />performa: Specificity","Cutoff: 0.72020202<br />value: 0.9975369<br />performa: Specificity","Cutoff: 0.72818182<br />value: 0.9975369<br />performa: Specificity","Cutoff: 0.73616162<br />value: 0.9975369<br />performa: Specificity","Cutoff: 0.74414141<br />value: 0.9975369<br />performa: Specificity","Cutoff: 0.75212121<br />value: 0.9975369<br />performa: Specificity","Cutoff: 0.76010101<br />value: 0.9975369<br />performa: Specificity","Cutoff: 0.76808081<br />value: 0.9975369<br />performa: Specificity","Cutoff: 0.77606061<br />value: 0.9975369<br />performa: Specificity","Cutoff: 0.78404040<br />value: 0.9975369<br />performa: Specificity","Cutoff: 0.79202020<br />value: 0.9975369<br />performa: Specificity","Cutoff: 0.80000000<br />value: 0.9975369<br />performa: Specificity"],"type":"scatter","mode":"lines","line":{"width":5.66929133858268,"color":"rgba(255,215,0,1)","dash":"solid"},"hoveron":"points","name":"Specificity","legendgroup":"Specificity","showlegend":true,"xaxis":"x","yaxis":"y","hoverinfo":"text","frame":null}],"layout":{"margin":{"t":43.7625570776256,"r":7.30593607305936,"b":40.1826484018265,"l":43.1050228310502},"font":{"color":"rgba(0,0,0,1)","family":"","size":14.6118721461187},"title":{"text":"Tradeoff model perfomance","font":{"color":"rgba(0,0,0,1)","family":"","size":17.5342465753425},"x":0,"xref":"paper"},"xaxis":{"domain":[0,1],"automargin":true,"type":"linear","autorange":false,"range":[-0.0295,0.8395],"tickmode":"array","ticktext":["0.0","0.1","0.2","0.3","0.4","0.5","0.6","0.7","0.8"],"tickvals":[-3.46944695195361e-18,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8],"categoryorder":"array","categoryarray":["0.0","0.1","0.2","0.3","0.4","0.5","0.6","0.7","0.8"],"nticks":null,"ticks":"","tickcolor":null,"ticklen":3.65296803652968,"tickwidth":0,"showticklabels":true,"tickfont":{"color":"rgba(77,77,77,1)","family":"","size":11.689497716895},"tickangle":-0,"showline":false,"linecolor":null,"linewidth":0,"showgrid":true,"gridcolor":"rgba(235,235,235,1)","gridwidth":0.66417600664176,"zeroline":false,"anchor":"y","title":{"text":"Probability Cut-off","font":{"color":"rgba(0,0,0,1)","family":"","size":14.6118721461187}},"hoverformat":".2f"},"yaxis":{"domain":[0,1],"automargin":true,"type":"linear","autorange":false,"range":[-0.05,1.05],"tickmode":"array","ticktext":["0.0","0.1","0.2","0.3","0.4","0.5","0.6","0.7","0.8","0.9","1.0"],"tickvals":[0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1],"categoryorder":"array","categoryarray":["0.0","0.1","0.2","0.3","0.4","0.5","0.6","0.7","0.8","0.9","1.0"],"nticks":null,"ticks":"","tickcolor":null,"ticklen":3.65296803652968,"tickwidth":0,"showticklabels":true,"tickfont":{"color":"rgba(77,77,77,1)","family":"","size":11.689497716895},"tickangle":-0,"showline":false,"linecolor":null,"linewidth":0,"showgrid":true,"gridcolor":"rgba(235,235,235,1)","gridwidth":0.66417600664176,"zeroline":false,"anchor":"x","title":{"text":"Value","font":{"color":"rgba(0,0,0,1)","family":"","size":14.6118721461187}},"hoverformat":".2f"},"shapes":[{"type":"rect","fillcolor":null,"line":{"color":null,"width":0,"linetype":[]},"yref":"paper","xref":"paper","x0":0,"x1":1,"y0":0,"y1":1}],"showlegend":true,"legend":{"bgcolor":null,"bordercolor":null,"borderwidth":0,"font":{"color":"rgba(0,0,0,1)","family":"","size":11.689497716895},"y":0.96751968503937},"annotations":[{"text":"Metrics","x":1.02,"y":1,"showarrow":false,"ax":0,"ay":0,"font":{"color":"rgba(0,0,0,1)","family":"","size":14.6118721461187},"xref":"paper","yref":"paper","textangle":-0,"xanchor":"left","yanchor":"bottom","legendTitle":true}],"hovermode":"closest","barmode":"relative"},"config":{"doubleClick":"reset","showSendToCloud":false,"displayModeBar":false},"source":"A","attrs":{"16e8cd6c5b":{"x":{},"y":{},"colour":{},"type":"scatter"}},"cur_data":"16e8cd6c5b","visdat":{"16e8cd6c5b":["function (y) ","x"]},"highlight":{"on":"plotly_click","persistent":false,"dynamic":false,"selectize":false,"opacityDim":0.2,"selected":{"opacity":1},"debounce":0},"shinyEvents":["plotly_hover","plotly_click","plotly_selected","plotly_relayout","plotly_brushed","plotly_brushing","plotly_clickannotation","plotly_doubleclick","plotly_deselect","plotly_afterplot","plotly_sunburstclick"],"base_url":"https://plot.ly"},"evals":[],"jsHooks":[]}</script><!--/html_preserve-->

Misal dari segi bisnis dibutuhkan Precision minimal 98%, maka menurut plot di atas kita bisa set threshold 0.6324, kemudian lakukan evaluasi ulang dengan confusion matrix ataupun ROC-AUC.


```r
threshold <- 0.6324
pred_class <- as.factor(ifelse(model$predicted_prob > threshold,
                               "spam", "ham"))

confusionMatrix(data = pred_class,
                reference = model$actual_label,
                positive = "spam")
```

```
#> Confusion Matrix and Statistics
#> 
#>           Reference
#> Prediction  ham spam
#>       ham  1215   27
#>       spam    3  148
#>                                                
#>                Accuracy : 0.9785               
#>                  95% CI : (0.9694, 0.9854)     
#>     No Information Rate : 0.8744               
#>     P-Value [Acc > NIR] : < 0.00000000000000022
#>                                                
#>                   Kappa : 0.8959               
#>                                                
#>  Mcnemar's Test P-Value : 0.00002679           
#>                                                
#>             Sensitivity : 0.8457               
#>             Specificity : 0.9975               
#>          Pos Pred Value : 0.9801               
#>          Neg Pred Value : 0.9783               
#>              Prevalence : 0.1256               
#>          Detection Rate : 0.1062               
#>    Detection Prevalence : 0.1084               
#>       Balanced Accuracy : 0.9216               
#>                                                
#>        'Positive' Class : spam                 
#> 
```
