# Unsupervised Learning





## FAQ

1. Bagaimana penerapan PCA di industri?

   PCA pada industri lebih sering digunakan untuk data preparation sama halnya seperti scaling, feature engineering, ataupun variable selection. PCA digunakan untuk mereduksi data besar menjadi data yang lebih kecil, secara sederhana dapat dikatakan mengurangi jumlah kolom pada data. Walaupun PCA mengurangi jumlah kolom pada data (mereduksi dimensi), PCA tetap mempertahankan semua variabel (menggunakan semua variabel). Sebelum mereduksi dimensi PCA akan merangkum terlebih dahulu semua informasi yang terdapat pada setiap variabel ke dalam bentuk PC, PC tersebut yang nantinya akan direduksi (dikurangi) dimensinya. Oleh karena itu, variabel yang digunakan jumlahnya tetap sama seperti data awal, hanya informasi (variansinya) saja yang berkurang. Berikut merupakan link eksternal yang dapat dijadikan sebagai bahan referensi [An Application of PCA](https://web.cs.ucdavis.edu/~vemuri/papers/pcaVisualization.pdf).

   Contoh permasalahan yang sering ditemui adalah klasifikasi dokumen. Saat ini semua administrasi dilakukan secara online/elektronik (tidak manual), adakalanya seorang nasabah/pelamar/customer harus melakukan upload dokumen. Sebelum adanya klasifikasi dokumen, pengecekkan kebenaran dokumen dilakukan secara manual. sehingga membutuhkan waktu yang cukup lama dan kapasitas penyimpanan yang relatif besar karena apps tidak mampu memilah mana dokumen yang sudah sesuai dan mana yang belum. Namun, permasalahan tersebut sudah mampu terjawab dengan adanya klasifikasi dokumen. Data untuk klasifikasi dokumen adalah data image yang jika dilakukan proses klasifikasi akan memerlukan komputasi yang relatif lama dibandingkan data tabular biasa. Oleh karena itu, perlu dilakukan PCA untuk mereduksi dimensi data image tersebut supaya komputasi saat proses klasifikasi bisa menjadi lebih cepat. Berikut merupakan link eksternal yang dapat dijadikan sebagai bahan referensi [Image Compression with PCA in R](https://www.r-bloggers.com/image-compression-with-pca-in-r/).

2. Apakah biplot dapat menampilkan PC lain selain PC1 dan PC2?

  Bisa tetapi informasi yang dijelaskan menjadi berkurang, karena secara default pada R PC1 dan PC2 merangkum informasi paling banyak. Berikut contoh membuat biplot dengan menggunakan PC lain (selain PC1 dan PC2):

```r
head(USArrests)
```

```
#>            Murder Assault UrbanPop Rape
#> Alabama      13.2     236       58 21.2
#> Alaska       10.0     263       48 44.5
#> Arizona       8.1     294       80 31.0
#> Arkansas      8.8     190       50 19.5
#> California    9.0     276       91 40.6
#> Colorado      7.9     204       78 38.7
```

Membuat PCA dari data `USArrests` dengan menggunakan fungsi `prcomp()`.

```r
pca_us <- prcomp(USArrests, scale = T)
```

Membuat visualisasi dari hasil PCA dengan menggunakan fungsi `biplot()`.

```r
# parameter `choices` dapat diganti sesuai PC yang ingin dibuat, secara default menggunakan  PC1 dan PC2 (choices = 1:2)
biplot(pca_us, choices = 2:3)
```

<img src="04-UL_files/figure-html/unnamed-chunk-4-1.png" width="672" style="display: block; margin: auto;" />

3. Dimensionality reduction mengatasi masalah high-dimensional data, permasalahan apa yang terdapat pada data berdimensi tinggi?

  -  menyulitkan pengolahan data, 

  -  memerlukan komputasi yang besar,

  -  tidak efisien secara waktu.

4. Perbedaan membuat PCA dengan menggunakan fungsi `prcomp()` dan `PCA()` dari library `FactoMiner`?

   Fungsi untuk membuat biplot di R:

  *  `biplot(prcomp())` -> base R

  *  `plot.PCA(PCA())` -> package FactoMineR

   kelebihan ketika membuat PCA dengan menggunakan fungsi `PCA()` dari library `FactoMiner` adalah bisa membuat biplot lebih spesifik (memisah dua grafik yang diajdikan satu -> **individu/variabel**) dan bisa **mengkombinasikan antara variabel numerik dan kategorik** dengan menggunakan fungsi `plot.PCA()`. 

5. Apakah terdapat best practice dalam menentukan jumlah PC yang digunakan pada PCA? 

   Penentuan jumlah PC yang digunakan bergantung pada kebutuhan analisa yang dilakukan. Namun, kembali pada tujuan awal melakukan PCA, yaitu untuk mereduksi dimensi supaya analisis lanjutan yang dilakukan memiliki waktu yang relatif cepat dan ruang penyimpanan yang lebih efisien. Sehingga, seringkali seorang analis menentapkan threshold lebih dari 70-75% informasi. Maksudnya jumlah PC yang digunakan adalah jumlah PC yang sudah merangkum kurang lebih 70-75% informasi. Namun, threshold tersebut sifatnya tidak mutlak artinya disesuaikan dengan kebutuhan analisis dan bisnis. Berikut merupakan link eksternal yang dapat dijadikan sebagai bahan referensi [How many components can I retrieve in principal component analysis?](https://www.researchgate.net/post/How_many_components_can_I_retrieve_in_principal_component_analysis).  

6. Bagaimana best practice dalam penentuan jumlah cluster?

   Fungsi `kmeans()` tidak dapat menentukan jumlah cluster secara otomatis. Jumlah cluster tetap ditentukan oleh user berdasarkan kebutuhan bisnis. Namun, secara statistik penentuan jumlah cluster dapat dilakukan berdasarkan penurunan wss. Secara sederhana, penurunan wss dapat divisualisasikan dengan menggunakan fungsi `fviz_nbclust()` dari library `factoextra`. Berikut contoh memvisualisasikan penurunan wss dengan menggunakan data `USArrests`:

```r
head(USArrests, 6)
```

```
#>            Murder Assault UrbanPop Rape
#> Alabama      13.2     236       58 21.2
#> Alaska       10.0     263       48 44.5
#> Arizona       8.1     294       80 31.0
#> Arkansas      8.8     190       50 19.5
#> California    9.0     276       91 40.6
#> Colorado      7.9     204       78 38.7
```

```r
# scaling data
USArrests_scale <- scale(USArrests)
```

Melakukan visualisasi penurunan wss dengan menggunakan fungsi `fviz_nbclust()` dari library `factoextra`.

```r
set.seed(100)
fviz_nbclust(USArrests_scale, method = "wss", kmeans)
```

<img src="04-UL_files/figure-html/unnamed-chunk-6-1.png" width="672" style="display: block; margin: auto;" />

Jumlah cluster yang dipilih adalah jumlah cluster yang ketika dilakukan penambahan cluster sudah tidak mengakibatkan penurunan wss yang signifikan (pada grafik bentuknya landai), kemudian disesuaikan dengan kebutuhan bisnis pada industri.

7. Apakah kita dapat memvisualisasikan biplot dengan 3 dimensi?

Untuk menampilkan biplot dengan 3 dimensi dapat menggunakan function `plot_ly()` dari package `plotly`. Berikut ini akan dicontohkan memvisualisasikan biplot dari PC1, PC2, PC3 dan juga akan dibedakan setiap titik observasi dengan cluster nya. Sebelum masuk ke visualisasi, akan dicari terlebih dahulu cluster untuk setiap observasi.

```r
# Read data in
whiskies <- read.csv("data/04-UL/whiskies.txt")
# Distillery column is the name of each whisky
rownames(whiskies) <- whiskies[,"Distillery"]

# remove RowID, Postcode, Latitude and Longitude
whiskies <- whiskies[,3:14]

whi_km <- kmeans(scale(whiskies), 4)
```

Setelah menggunakan `kmeans()` untuk mendapatkan cluster, berikutnya kita lakukan PCA dan membentuk PC yang diperoleh dalam bentuk data frame.

```r
whis.pca<-PCA(whiskies, graph = F,scale.unit = T)
df_pca <- data.frame(whis.pca$ind$coord) %>% 
          bind_cols(cluster = as.factor(whi_km$cluster))
head(df_pca)
```

```
#>         Dim.1      Dim.2      Dim.3      Dim.4       Dim.5 cluster
#> 1 -0.65565655  1.2056463 -0.1663438 -0.7807432  0.14526590       2
#> 2 -2.31263102  3.7479878  1.3669186  0.8719922  0.69366566       2
#> 3 -1.60215288 -0.6640822 -0.2972053 -1.1027897 -0.01535638       4
#> 4  5.41363278  0.2448746  1.2101422 -0.7483052 -0.19536723       3
#> 5  0.12164922  0.4127927 -0.3044621 -1.2705758  1.49597271       1
#> 6  0.09941062 -1.3966133 -1.2024542  1.6549138 -0.28659985       4
```
 
Langkah berikutnya adalah memvisualisasikan PC dan membedakan warna observasi berdasarkan cluster nya.

```r
plot_ly(df_pca,x = ~Dim.1, y = ~Dim.2, z = ~Dim.3, color = ~cluster)
```

8. Bagaimana implementasi PCA pada data pre-processing?

Berikut ini aku dilakukan implementasi PCA pada tahapan data pre-processing dengan menggunakan data `attrition`.

```r
attrition <- read.csv("data/04-UL/attrition.csv")

head(attrition, 5)
```

```
#>   attrition age   business_travel daily_rate           department
#> 1       yes  41     travel_rarely       1102                sales
#> 2        no  49 travel_frequently        279 research_development
#> 3       yes  37     travel_rarely       1373 research_development
#> 4        no  33 travel_frequently       1392 research_development
#> 5        no  27     travel_rarely        591 research_development
#>   distance_from_home education education_field employee_count employee_number
#> 1                  1         2   life_sciences              1               1
#> 2                  8         1   life_sciences              1               2
#> 3                  2         2           other              1               4
#> 4                  3         4   life_sciences              1               5
#> 5                  2         1         medical              1               7
#>   environment_satisfaction gender hourly_rate job_involvement job_level
#> 1                        2 female          94               3         2
#> 2                        3   male          61               2         2
#> 3                        4   male          92               2         1
#> 4                        4 female          56               3         1
#> 5                        1   male          40               3         1
#>                job_role job_satisfaction marital_status monthly_income
#> 1       sales_executive                4         single           5993
#> 2    research_scientist                2        married           5130
#> 3 laboratory_technician                3         single           2090
#> 4    research_scientist                3        married           2909
#> 5 laboratory_technician                2        married           3468
#>   monthly_rate num_companies_worked over_18 over_time percent_salary_hike
#> 1        19479                    8       y       yes                  11
#> 2        24907                    1       y        no                  23
#> 3         2396                    6       y       yes                  15
#> 4        23159                    1       y       yes                  11
#> 5        16632                    9       y        no                  12
#>   performance_rating relationship_satisfaction standard_hours
#> 1                  3                         1             80
#> 2                  4                         4             80
#> 3                  3                         2             80
#> 4                  3                         3             80
#> 5                  3                         4             80
#>   stock_option_level total_working_years training_times_last_year
#> 1                  0                   8                        0
#> 2                  1                  10                        3
#> 3                  0                   7                        3
#> 4                  0                   8                        3
#> 5                  1                   6                        3
#>   work_life_balance years_at_company years_in_current_role
#> 1                 1                6                     4
#> 2                 3               10                     7
#> 3                 3                0                     0
#> 4                 3                8                     7
#> 5                 3                2                     2
#>   years_since_last_promotion years_with_curr_manager
#> 1                          0                       5
#> 2                          1                       7
#> 3                          0                       0
#> 4                          3                       0
#> 5                          2                       2
```

Sebelum melakukan PCA terlebih dahulu dilakukan cross validation, yaitu membagi data menjadi **training set** untuk proses pemodelan dan **testing set** untuk melakukan evaluasi. Namun, data train dan data test tidak langsung dimasukkan ke dalam sebuah objek melainkan dilakukan PCA terlebih dahulu.

Cross validation akan dilakukan dengan menggunakan fungsi `initial_split()` dari library `rsample`. Fungsi tersebut akan melakukan proses sampling untuk cross validation dengan metode **stratified random sampling**, sehingga proporsi target variabel pada data awal, akan dipertahankan baik pada training set maupun testing set.

```r
set.seed(417)
splitted <- initial_split(data = attrition, prop = 0.8, strata = "attrition")

splitted
```

```
#> <1177/293/1470>
```

Melakukan tahapan data preparation yang didalamnya termasuk melakukan PCA. Data preparation yang akan dilakukan adalah menghapus variabel yang dianggap tidak berpengaruh, membuang variabel yang variansinya mendekati 0 (tidak informatif), melakukan scaling, dan melakukan PCA. Proses yang dilakukan pada tahapan data preparation akan dilakukan dengan menggunakan fungsi dari library `recipes`, yaitu `step_rm()` untuk menghapus variabel, `step_nzv()` untuk membuang variabel yang variansinya mendekati 0,`step_center()` dan `step_scale()` untuk melakukan scaling, terakhir `step_pca()` untuk melakukan PCA.

```r
rec <- recipe(attrition ~ ., training(splitted)) %>% 
  step_rm(employee_count, employee_number) %>%
  step_nzv(all_predictors()) %>% 
  step_center(all_numeric()) %>% 
  step_scale(all_numeric()) %>% 
  step_pca(all_numeric(), threshold = 0.8) %>% 
  prep()
```

Setelah mendefinisikan proses data preparation pada objek `rec`, selanjutnya proses tersebut diterapkan ke data train menggunakan fungsi `juice()` dan ke data test menggunakan fungsi `bake()` dari library `recipes`.

```r
train <- juice(rec)

# melihat hasil data train setelah dilakukan tahapan data preparation
head(train, 5)
```

```
#> # A tibble: 5 x 21
#>   business_travel department education_field gender job_role marital_status
#>   <fct>           <fct>      <fct>           <fct>  <fct>    <fct>         
#> 1 travel_rarely   sales      life_sciences   female sales_e… single        
#> 2 travel_frequen… research_… life_sciences   male   researc… married       
#> 3 travel_rarely   research_… other           male   laborat… single        
#> 4 travel_frequen… research_… life_sciences   female researc… married       
#> 5 travel_rarely   research_… medical         male   laborat… married       
#> # … with 15 more variables: over_time <fct>, attrition <fct>, PC01 <dbl>,
#> #   PC02 <dbl>, PC03 <dbl>, PC04 <dbl>, PC05 <dbl>, PC06 <dbl>, PC07 <dbl>,
#> #   PC08 <dbl>, PC09 <dbl>, PC10 <dbl>, PC11 <dbl>, PC12 <dbl>, PC13 <dbl>
```


```r
test <- bake(rec, testing(splitted))

# melihat hasil data test setelah dilakukan tahapan data preparation
head(test, 5)
```

```
#> # A tibble: 5 x 21
#>   business_travel department education_field gender job_role marital_status
#>   <fct>           <fct>      <fct>           <fct>  <fct>    <fct>         
#> 1 travel_rarely   research_… medical         female laborat… married       
#> 2 travel_rarely   research_… life_sciences   male   laborat… divorced      
#> 3 travel_rarely   research_… medical         male   healthc… married       
#> 4 travel_rarely   research_… medical         male   laborat… divorced      
#> 5 travel_rarely   research_… life_sciences   male   laborat… single        
#> # … with 15 more variables: over_time <fct>, attrition <fct>, PC01 <dbl>,
#> #   PC02 <dbl>, PC03 <dbl>, PC04 <dbl>, PC05 <dbl>, PC06 <dbl>, PC07 <dbl>,
#> #   PC08 <dbl>, PC09 <dbl>, PC10 <dbl>, PC11 <dbl>, PC12 <dbl>, PC13 <dbl>
```

Dari output di atas diketahui bahwa variabel numerik sudah berbentuk sebuah PC. Selanjutnya, data sudah siap dilanjutkan ketahap modeling.


9. Bagaimana implementasi visualisasi PCA menggunakan package `factoextra`?

Kita akan mencoba melakukan visualisasi pada data setelah dilakukan PCA dengan menggunakan data `loan`.

```r
loan <- read.csv("data/04-UL/loan2017Q4.csv")

head(loan, 5)
```

```
#>   initial_list_status            purpose int_rate installment annual_inc   dti
#> 1                   w debt_consolidation    14.08      675.99     156700 19.11
#> 2                   f debt_consolidation     9.44      480.08      50000 19.35
#> 3                   w debt_consolidation    28.72     1010.30      25000 65.58
#> 4                   w debt_consolidation    13.59      484.19     175000 12.60
#> 5                   w     major_purchase    15.05      476.33     109992 10.00
#>   verification_status grade revol_bal inq_last_12m delinq_2yrs home_ownership
#> 1     Source Verified     C     21936            3           0       MORTGAGE
#> 2        Not Verified     B      5457            1           1           RENT
#> 3            Verified     F     23453            0           0            OWN
#> 4        Not Verified     C     31740            0           0       MORTGAGE
#> 5        Not Verified     C      2284            3           0       MORTGAGE
#>   not_paid  log_inc verified grdCtoA
#> 1        0 11.96209        1       0
#> 2        1 10.81978        0       1
#> 3        1 10.12663        1       0
#> 4        1 12.07254        0       0
#> 5        0 11.60816        0       0
```

Sebelum melakukan PCA kita akan melakukan tahapan data preparation terlebih dahulu dengan membuang variabel `initial_list_status`, `home_ownership`, dan `not_paid` karena visualisasi yang akan dibuat tidak memerlukan insight dari ketiga variabel tersebut.

```r
loan_clean <- loan %>% 
  select(-c(initial_list_status, home_ownership, not_paid))
```

Membuat PCA dengan menggunakan fungsi `PCA()` dari library `FactoMiner`. Parameter yang digunakan adalah:

  -  `ncp`: Jumlah PC yang akan dihasilkan. Secara default fungsi `PCA()` hanya akan menampilkan 5 PC awal (5 PC yang membawa informasi paling banyak).

  -  `quali.sup`: Nomor kolom dari variabel kategorik.

  -  `graph`: Sebuah logical value. T akan menampilkan hasil visualisasi, F tidak menampilkan hasil visualisasi. Secara default fungsi `PCA()` akan langsung menampilkan hasil visualisasi.

```r
pca_loan <- PCA(loan_clean, ncp = 10, quali.sup = c(1, 6, 7), graph = F)
```

Setelah membuat PCA, selanjutnya adalah membuat visualisasi dari hasil PCA. Kita akan membuat individual plot menggunakan fungsi `fviz_pca_ind()` dari library `factoextra`. Parameter yang digunakan adalah:

  -  Hasil PCA

  -  `habillage`: Variabel kategori yang dipilih, setiap individu akan dibedakan berdasarkan variabel kategori yang dipilih.

  -  `select.ind`: Jumlah individu dengan kontribusi tertinggi yang ingin dilihat.

```r
fviz_pca_ind(pca_loan, habillage = 6, select.ind = list(contrib = 10))
```

<img src="04-UL_files/figure-html/unnamed-chunk-18-1.png" width="672" style="display: block; margin: auto;" />

Plot individu di atas hanya menampilkan 10 observasi yang memberikan informasi tertinggi terhadap PC1 dan PC2. Namun, terdapat lebih dari 10 titik observasi yang terdapat pada plot di atas karena terdapat titik observasi yang merupakan titik pusat dari tiap status verifikasi.

10. Bagaimana implementasi visualisasi K-means clustering menggunakan package `factoextra`?

Kita akan mencoba melakukan visualisasi hasil clustering dengan menggunakan data `USArrests`.

```r
head(USArrests, 5)
```

```
#>            Murder Assault UrbanPop Rape
#> Alabama      13.2     236       58 21.2
#> Alaska       10.0     263       48 44.5
#> Arizona       8.1     294       80 31.0
#> Arkansas      8.8     190       50 19.5
#> California    9.0     276       91 40.6
```

```r
# scaling data `USArrests`
USArrests_scale <- scale(USArrests)
```

Menentukan jumlah cluster yang akan dibuat berdasarkan penurunan wss. Supaya lebih mudah menentukan penurunan wss yang sudah tidak signifikan ketika menambah jumlah cluster, maka dibuat visualisasinya dengan menggunakan fungsi `fviz_nbclust()` dari library `factoextra`.

```r
set.seed(100)
fviz_nbclust(USArrests_scale, method = "wss", kmeans)
```

<img src="04-UL_files/figure-html/unnamed-chunk-20-1.png" width="672" style="display: block; margin: auto;" />

Melakukan k-means clustering dengan jumlah cluster 5 berdasarkan hasil penurunan wss di atas menggunakan fungsi `kmeans()`. 

```r
set.seed(100)
USArrests_cl <- kmeans(USArrests_scale, 5)
```

Membuat visualisasi hasil cluster dengan menggunakan fungsi `fviz_cluster()` dari library `factoextra`.

```r
# `USArrests` bisa diganti dengan yang sudah dilakukan scaling `USArrests_scale` 
fviz_cluster(USArrests_cl, USArrests)
```

<img src="04-UL_files/figure-html/unnamed-chunk-22-1.png" width="672" style="display: block; margin: auto;" />

Mengkombinasikan visualisasi hasil clusterig dengan PCA. Untuk melakukan hal tersebut kita harus menambahkan kolom cluster pada data `USArrests`.

```r
USArrests_clean <- USArrests %>% 
  mutate(cluster = USArrests_cl$cluster)

head(USArrests_clean, 5)
```

```
#>   Murder Assault UrbanPop Rape cluster
#> 1   13.2     236       58 21.2       1
#> 2   10.0     263       48 44.5       4
#> 3    8.1     294       80 31.0       4
#> 4    8.8     190       50 19.5       5
#> 5    9.0     276       91 40.6       4
```

Kita akan mengubah nama baris yang awalnya berupa indeks menjadi nama negara sesuai dengan data `USArrests`.

```r
rownames(USArrests_clean) <- rownames(USArrests)

head(USArrests_clean, 5)
```

```
#>            Murder Assault UrbanPop Rape cluster
#> Alabama      13.2     236       58 21.2       1
#> Alaska       10.0     263       48 44.5       4
#> Arizona       8.1     294       80 31.0       4
#> Arkansas      8.8     190       50 19.5       5
#> California    9.0     276       91 40.6       4
```

Membuat PCA terlebih dahulu untuk mengkombinasikan visualisasi hasil clustering dengan PCA dengan menggunakan `PCA()`.

```r
pca_USArrest <- PCA(USArrests_clean, quali.sup = 5, graph = F)
```

Mengkombinasikan visualisasi hasil clustering dan PCA menggunakan fungsi `fviz_pca_biplot()` dari library `factoextra`. Parameter yang digunakan adalah:

  -  Hasil PCA

  -  `habillage`: Variabel kategori yang dipilih, setiap individu akan dibedakan berdasarkan variabel kategori yang dipilih.

  -  `addEllipses`: Sebuah logical value. T akan menambah elips untuk ssetiap cluster, F sebaliknya. Secara default fungsi `fviz_pca_biplot()` tidak akan menambah elips pada plot individu.

```r
fviz_pca_biplot(pca_USArrest, habillage = 5, addEllipses = T)
```

<img src="04-UL_files/figure-html/unnamed-chunk-26-1.png" width="672" style="display: block; margin: auto;" />

Dari plot di atas terlihat bahwa antar cluster saling tumpang tindih, namun kenyataannya antar cluster pasti memiliki observasi/individu yang unik. Hal tersebut terjadi karena kita mencoba untuk memvisualisasikan cluster yang dibentuk dari 4 variabel/dimensi mejadi 2 variabel/dimensi saja.

## Mathematics Concept

**1. Tujuan: membuat axis baru yang dapat merangkum informasi data**

<img src="assets/04-UL/pca1.png" width="60%" style="display: block; margin: auto;" />

Kita akan menggunakan data generate yang disimpan pada objek A, yang terdiri dari variabel x dan y.

```r
set.seed(100)
x <- runif(200)
A <- data.frame(x=x, y=-x+runif(100, 1.05, 1.25))

# sebelum menghitung varian-kovarian  harus dilakukan scaling trlebih dahulu, karena variance dan covariance sangat bergantung pada interval nilai dari data
A <- scale(A, center = T)
head(A)
```

```
#>                x             y
#> [1,] -0.69524199  0.5781964712
#> [2,] -0.87017881  1.1453429992
#> [3,]  0.15879719  0.1183517145
#> [4,] -1.57312115  1.7370570727
#> [5,] -0.13375526 -0.0003546811
#> [6,] -0.08059893  0.3262449661
```

Membuat visualisasi data yang disimpan pada objek A.

```r
plot(A, cex=0.4)
```

<img src="04-UL_files/figure-html/unnamed-chunk-29-1.png" width="672" style="display: block; margin: auto;" />

Variabel x dan y berkorelasi secara negatif, karena variabel y dibentuk dari operasi matematika dari variabel x (dengan kata lain variabel y mengandung informasi dari x). 

**2. PC merangkum informasi dari actual data sehingga akan dihitung variance-covariance (variance-covaiance merepresentasikan informasi yang terkandung pada suatu data)** 

```r
var(A)
```

```
#>           x         y
#> x  1.000000 -0.982719
#> y -0.982719  1.000000
```

```r
class(var(A))
```

```
#> [1] "matrix"
```

```r
# bisa menggunakan `cov()` selain menggunakan `var()` untuk menghitung variance-covariance
# cov(A)
# cor(A)
```

Jika diperhatikan variance-covariance yang dihasilkan berupa matriks, dalam aljabar terdapat beberapa operasi perkalian untuk kelas matriks:

- **Vektor x skalar (konstanta)**

```r
matrix(c(2,3)) %*% 2
```

```
#>      [,1]
#> [1,]    4
#> [2,]    6
```

Membuat plot untuk melihat vektor awal

```r
plot(2, 3)
lines(x = c(0, 2), y = c(0, 3))
```

<img src="04-UL_files/figure-html/unnamed-chunk-32-1.png" width="672" style="display: block; margin: auto;" />

Membuat plot untuk membandingkan vektor awal dan setelah dilakukan operasi perkalian dengan skalar (konstanta)

```r
plot(x = c(2, 4), y = c(3, 6))
lines(x = c(0, 4), y = c(0, 6))
```

<img src="04-UL_files/figure-html/unnamed-chunk-33-1.png" width="672" style="display: block; margin: auto;" />

> Operasi perkalian antara vektor x skalar (konstanta) akan memperbesar vektor dengan arah yang sama.

- **Matriks x vektor**

```r
matrix(1:4, nrow = 2) %*% matrix(c(2, 3))
```

```
#>      [,1]
#> [1,]   11
#> [2,]   16
```

Membuat plot untuk membandingkan vektor awal dan setelah dilakukan operasi perkalian dengan matriks

```r
plot(x = c(2, 11), y = c(3, 16))
lines(x = c(0, 2), y = c(0, 3))
lines(x = c(0, 11), y = c(0, 16))
```

<img src="04-UL_files/figure-html/unnamed-chunk-35-1.png" width="672" style="display: block; margin: auto;" />

Jika diperhatikan kedua vektor tersebut seperti berada dalam satu garis karena hampir sejajar, namun jika dicek nilai slope ($y/x$) akan sangat jelas berbeda.

```r
# vektor awal
3/2
```

```
#> [1] 1.5
```

```r
# vektor setelah dilakukan operasi perkalian dengan matriks
16/11
```

```
#> [1] 1.454545
```

> Operasi perkalian antara matriks x vektor akan mengubah besar dan arah vektor

- **Matriks identitas x vektor**

```r
matrix(c(1, 0, 0, 1), nrow = 2) %*% matrix(c(2, 3))
```

```
#>      [,1]
#> [1,]    2
#> [2,]    3
```

> Operasi perkalian antara matriks x vektor akan mengubah besar dan arah vektor, namun **terdapat matriks yang jika dikalikan dengan vektor tidak akan mengubah besar dan arah vektor, yaitu matriks identitas**.

- **Matriks rotasi x vektor** 

```r
matrix(c(-1, 0, 0, -1), nrow = 2) %*% matrix(c(-3, 2))
```

```
#>      [,1]
#> [1,]    3
#> [2,]   -2
```

Membuat plot untuk melihat vektor awal

```r
plot(-3, 2)
lines(x = c(0, -3), y = c(0, 2))
```

<img src="04-UL_files/figure-html/unnamed-chunk-39-1.png" width="672" style="display: block; margin: auto;" />

Membuat plot untuk membandingkan vektor awal dan setelah dilakukan operasi perkalian dengan matriks rotasi

```r
plot(3, -2)
lines(x = c(0, 3), y = c(0, -2))
```

<img src="04-UL_files/figure-html/unnamed-chunk-40-1.png" width="672" style="display: block; margin: auto;" />

> Operasi perkalian antara matriks x vektor akan mengubah besar dan arah vektor, namun **terdapat matriks yang jika dikalikan dengan vektor hanya akan mengubah arah vektor, yaitu matriks rotasi**.

<img src="assets/04-UL/rotation.gif" width="60%" style="display: block; margin: auto;" />

- **Matriks x eigen vektor**

> Operasi perkalian antara matriks x vektor akan mengubah besar dan arah vektor. Namun, terdapat vektor yang unik yang jika dikalikan dengan matriks hasilnya sama dengan mengalikan vektor dengan skalar.

Skalar tersebut adalah konstanta yang disebut sebagai eigen value. Ketika kita mengalikan matriks A dengan eigen vector x, hasilnya adalah konstanta $\lambda$ dikalikan x. Maka persamaannya adalah:

$$A x = \lambda x $$

dimana:

- $A$ merupakan matriks varian-kovarian 
- $x$ merupakan eigen vector
- $\lambda$ merupkan skalar (konstanta) yang disebut eigen value. 

Eigen vektor tersebut digunakan sebagai transformasi untuk mengubah arah/menentukan arah axis baru yang lebih bisa merangkum informasi pada actual data.

**3. Variance-covariance yang memuat informasi pada actual data akan digunakan untuk memperoleh eigen vektor (transformasi) dan eigen value.**

```r
eigen(var(A))
```

```
#> eigen() decomposition
#> $values
#> [1] 1.98271899 0.01728101
#> 
#> $vectors
#>            [,1]       [,2]
#> [1,] -0.7071068 -0.7071068
#> [2,]  0.7071068 -0.7071068
```

Eigen value memuat jumlah informasi yang dirangkum oleh setiap PC, sehingga total eigen value akan sama dengan jumlah variabel pada actual data.

```r
1.98271899 + 0.01728101
```

```
#> [1] 2
```

**4. Membuat new data (PC) dari hasil perkalian antara actual data dengan eigen vektor (transformasi).**

New data tersebut akan memuat informasi yang sama dengan actual data dengan arah yang berbeda dari actual data.

**new data = actual data x eigen vektor**


```r
# dim(200x2).dim(2x2)
hasil_pc1 <- A %*% eigen(var(A))$vectors
```
