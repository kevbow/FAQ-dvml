# Regression Model






1. Bagaimana penanganan data kategorik pada model linear regression?

   Dengan menggunakan function `lm` pada R otomatis akan mengubah tipe data kategorik menjadi dummy variabel. Dummy variable berfungsi untuk mengkuantitatifkan variabel yang bersifat kualitatif (kategorik). Dummy variabel hanya mempunyai dua nilai yaitu 1 dan 0. Dummy memiliki nilai 1 untuk salah satu kategori dan nol untuk kategori yang lain. Jika terdapat sebanyak `k` kategori untuk  suatu prediktor maka akan ditransformasi menjadi `k-1` dummy.

2. Mengapa untuk asumsi normality yang harus berdistribusi normal adalah error/residual ?

   Jika residual berdistribusi normal, itu artinya residual cenderung berkumpul di titik sekitar 0, dapat dikatakan hasil prediksi tidak terlalu melenceng jauh dari data actual.

   Error yang tidak berdistribusi normal disebabkan oleh:

-  distribusi target variabel memang tidak normal
-  Model yang digunakan tidak cocok, misal hubungan antara prediktor dengan target tidak linier melainkan kudratik/eksponensial/dll walaupun target variabel memiliki distribusi normal. 
-  Selain itu, error harus berdistribusi normal terkait dengan pengujian-pengujian parameter (beta/koefisien regresi) secara statistik (F-test, t-test, dan confidence interval).
-  Terdapat banyak data outlier

3. Untuk prediktor kategorik, bagaimana jika terdapat kategori yang tidak signifikan (p value > alpha)? apakah prediktor tersebut masih dianggap signifikan mempengaruhi target?

   Untuk variabel kategorik ketika salah satu variabel signifikan, kita anggap levels lainnya juga signifikan.

4. Pada fungsi `lm` sudah otomatis melakukan transformasi data kategorik dengan level pertama yang dijadikan basis. Bagaimana jika dilakukan reorder level (mengubah urutan level), apakah akan mengubah hasil pemodelan?

   Hasil pemodelan tidak akan berubah, mengubah urutan level hanya akan mengubah basis yang digunakan. 

5. Bagaimana jika terdapat prediktor yang tidak signifikan, tetapi secara bisnis seharusnya prediktor tersebut berpengaruh terhadap target?

   Ketika variabel yang kita gunakan tidak signifikan secara statistik, namun secara bisnis berpengaruh terhadap target yang dimiliki, kita akan tetap mempertahankan variabel tersebut, banyak faktor yang menyebabkan variabel tersebut tidak signikan, bisa jadi karena data yang dimiliki tidak cukup banyak, banyak data oulier, atau ragam data yang hanya sedikit.

6. Mengapa perlu dilakukan pengecekkan asumsi pada metode regresi linier?

   Pengecekkan asumsi dilakukan terkait dengan pengujian-pengujian parameter (beta/koefisien regresi) secara statistik (F-test, t-test, dan confidence interval). Ketika semua asumsi terpenuhi model dapat dikatakan `BLUE` (Best Linear Unbiased Estimator).

7. Jika sudah dilakukan berbagai alternatif untuk pemenuhan asumsi, namun masih terdapat asumsi yang tidak terpenuhi apa yang harus dilakukan?

   Ketika sudah dilakukan berbagai alternatif untuk memenuhi asumsi namun asumsi masih tidak terpenuhi, itu artinya data yang kita miliki tidak cocok menggunakan regresi linear, dapat dicoba dengan model lain.

8. Bagaimana jika diperoleh nilai AIC negatif?

   AIC dapat bernilai negatif atupun positif yang disebabkan oleh nilai dari fungsi maksimum likelihood berikut: 

   `AIC = 2k âˆ’ 2ln(L)`, dimana `k` merupakan jumlah parameter (jumlah prediktor dan intersep) dan `L` merupakan nilai dari fungsi maksimum likelihood.

   Namun, pada pemilihan model nilai AIC yang dilihat adalah nilai AIC yang sudah diabsolutkan. Sehingga tanda negatif/positif pada hasil AIC tidak berpengaruh dalam proses pemilihan model. Model yang dipilih adalah model yang memiliki nilai abolut AIC terkecil, hal ini mengindikasikan bahwa semakin sedikit model tersebut kehilangan informasi yang dibawa. [Negative values for AIC](https://stats.stackexchange.com/questions/84076/negative-values-for-aic-in-general-mixed-model)

9. Perbedaan dari R-squared dan Adjusted R-squared?

    R-squared memperhitungkan variasi dari semua variabel independen terhadap variabel dependen. Sehingga setiap penambahan variabel independen akan meningkatkan nilai R-squared. Sedangkan pada adjusted r-squared akan memperhitungan variasi dari variabel independen yang signifikan terhadap variabel dependen. Oleh karena itu, pada multiple linear regression disarankan untuk melihat nilai Adjusted R-squared.

10. Apa itu outlier?

    Data observasi yang terlihat sangat berbeda jauh dari observasi-observasi lainnya dan muncul dalam bentuk nilai ekstrim baik untuk sebuah variabel tunggal atau kombinasi.

11. Cara yang dapat dilakukan untuk tuning model regresi?

    Banyak cara yang dapat dilakukan untuk tuning model regresi, salah satunya adalah dengan deteksi outlier pada data observasi. Deteksi outlier dari data yang dimiliki, apakah dengan atau tanpa data outlier tersebut akan mengganggu perfomance model yang dimiliki.

12. Untuk apa ada p-value di output regresi jika sebelumnya kita sudah melakukan uji korelasi?

    Uji korelasi pada preprocessing data dilakukan untuk melihat secara umum apakah variabel prediktor dan target terdapat hubungan kuat atau tidak. Sedangkan uji pvalue pada output regresi pada setiap variabel prediktor menyatakan apakah setiap variabel prediktor benar-benar mempengaruhi target secara statistik atau tidak.

13. Uji statistik apa yang dapat digunakan untuk uji normalitas dengan lebih dari 5000 observasi?

Uji normalitas dengan observasi yang lebih dari 5000 dapat menggunakan uji Kolmogorov Smirnov dengan code sebagai berikut:


```r
ks.test(model$residuals, "pnorm", mean = mean(model$residuals), sd = sd(model$residuals))
```

14. Bagaimana jika target variabel yang dimiliki berupa bilangan diskrit, apakah bisa dilakukan analisis regresi?

    Untuk analisis regresi dengan target variabel berupa bilangan diskrit dapat menggunakan regresi poisson. Untuk detail lengkapnya dapat dilihat di link berikut: [Regresi Poisson](https://algotech.netlify.com/blog/poisson-regression-and-neg-ative-binomial-regression/)

15. Bagaimana jika ingin melakukan `linearity test` sekaligus untuk setiap predictor terhadap `target variable`?

Untuk melakukan linearity test, kita dapat menggunakan function `cor.test`

```r
copiers <- read.csv("data/01-RM/copiers.csv") %>% select(-Row.ID)
cor.test(copiers$Sales, copiers$Profit)
```

```
#> 
#> 	Pearson's product-moment correlation
#> 
#> data:  copiers$Sales and copiers$Profit
#> t = 21.26, df = 60, p-value < 0.00000000000000022
#> alternative hypothesis: true correlation is not equal to 0
#> 95 percent confidence interval:
#>  0.9013320 0.9632858
#> sample estimates:
#>       cor 
#> 0.9395785
```
Dengan Pearson's hypothesis test sebagai berikut:

H0: Korelasi tidak signifikan

H1: Korelasi signifikan

Sedangkan untuk melakukan linearity test sekaligus untuk setiap predictor dapat membuat function sebagai berikut:


```r
cor.test.all <- function(data,target) {
  names <- names(data %>% select_if(is.numeric))
  df <- NULL
  for (i in 1:length(names)) {
    y <- target
    x <- names[[i]] 
    p_value <- cor.test(data[,y], data[,x])[3]
    temp <- data.frame(x = x,
                       y = y,
                       p_value = as.numeric(p_value))
    df  <- rbind(df,temp)
  }
  return(df)
}

cor.test.all(data = copiers,target ="Profit")
```

```
#>          x      y                               p_value
#> 1    Sales Profit 0.00000000000000000000000000001271056
#> 2 Quantity Profit 0.00000000076036803959617475451651658
#> 3 Discount Profit 0.00044956416337473974241881191638015
#> 4   Profit Profit 0.00000000000000000000000000000000000
```
