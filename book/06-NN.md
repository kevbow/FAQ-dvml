# Neural Network and Deep Learning




```r
library(rsample)
library(recipes)
library(keras)
```

1. Berapa jumlah hidden layer dan nodes untuk setiap hidden layer secara best practice dalam membangun arsitektur neural network (ANN) ?

- Kebanyakan orang menggunakan minimal 2 hidden layer, namun tidak menutup kemungkinan menggunakan lebih dari 2 ataupun kurang dari 2 hidden layer.
- Jumlah nodes biasanya semakin mengecil ketika hidden layers semakin dekat dengan output layer. Tujuannya adalah untuk melihat fitur dengan lebih spesifik. 
- Kebanyakan orang menggunakan angka biner $2^{n}$ seperti 1, 2, 4, 8, 16, 32, 64, 128, 256, dst karena neural network merupakan metode yang berasal dari orang computer science dan mathematics yang biasa menggunakan angka biner.

2. Fungsi aktivasi apa yang sering digunakan ketika membuat arsitktur neural network ?

- Pada hidden layer biasa digunakan fungsi aktivasi `relu` karena `relu` melakukan transformasi data dengan mengubah nilai negatif menjadi 0 dan membiarkan nilai positif, sehingga semakin ke belakang informasi yang dibawa tidak banyak berkurang.
- Pada output layer: jika casenya adalah regresi digunakan fungsi aktivasi `linear`, jika casenya adalah klasifikasi biner digunakan fungsi aktivasi `sigmoid`, dan jika casenya adalah klasifikasi multiclass digunakan fungsi aktivasi `softmax`.

3. Bagaimana menentukan batch size dan jumlah epoch ?

- Batch size biasanya menggunakan angka yang dapat membagi habis jumlah data, supaya data yang tersedia dapat digunakan secara keseluruhan (tidak ada yang tidak terpakai). Contoh:
Jika data train terdiri dari 800 observasi, kita bisa menggunakan batch size 200 yang dapat embagai habis 80 observasi.
- Jumlah epoch dimulai dari angka yang kecil terlebih dahulu supaya komputasi yang dilakukan tidak terlalu lama, kemudian dilihat apakah error dan accuracy yang dhasilkan sudah konvergen atau belum. Jika belum bisa menambaha jumlah epoch sedikit demi sedikit, dan sebaliknya.

4. Bagaimana menentukan learning rate yang tepat ?

   Learning rate berfungsi mempercepat atau memperlambat besaran update error.

- Semakin besar learning rate, maka error/accuracy akan semakin cepat konvergen. Namun, bisa saja titik error paling minimum (global optimum) terlewat.
- Semakin kecil learning rate, maka terdapat kemungkinan yang lebih besar untuk sampai di titik error paling minimum (global optimum). Namun, error/accuracy akan lebih lama konvergen.

5. Optimizer apa yang paling sering digunakan ?

   Optimizer merupakan fungsi yang digunakan untuk mengoptimumkan error (memperkecil error). Secara sederhana untuk mengoptimumkan suatu fungsi bisa melalui fungsi turunan, pada neural network disebut `sgd.` Namun, `sgd` memiliki beberapa kekurangan sehingga mulai banyak yang memperbaiki fungsi `sgd` tersebut. Untuk sekarang ini salah satu optimizer yang cukup terkenal adalah `adam` sebagai optimizer yang merupakan perbaikan dari `sgd` karena optimizer tersebut dapat mengupdate/menyesuaikan momentum ketika proses optimisasi. Berikut link eksternal yang dapat dijadikan sebagai bahan referensi [Adaptive Moment Estimation (Adam)](https://ruder.io/optimizing-gradient-descent/index.html#adam)

   Selain tips di atas berikut link eksternal yang dapat dijadikan referensi dalam membangun arsitektur neural network [Rules-of-thumb for building a Neural Network](https://towardsdatascience.com/17-rules-of-thumb-for-building-a-neural-network-93356f9930af)

6. Perbedaan metode-metode machine learning dengan neural network dan deep learning ?

- Neural network bukan merupakan metode yang berasal dari orang statistik melainkan lahir dari pemikiran orang-orang computer science dan math.
- Neural network merupakan salah satu metode machine learning, neural network yang arsitekturnya sudah cukup rumit sering disebut sebagai deep learning. Neural network memilki `1` hidden layer, sementara deep learning memiliki `> 1` hidden layer.

   Berikut merupakan link eksternal yang dapat dijadikan sebagai bahan referensi [Deep learning & Machine learning: whatâ€™s the difference?](https://parsers.me/deep-learning-machine-learning-whats-the-difference/)

7. Bagaimana mentransformasikan prediktor data kategorik menjadi variabel dummy?

Kita akan menggunakan data `attrition` yang memiliki variabel kategorik untuk dilakukan dummy transformation sebelum menggunakan metode neural network.

```r
attrition <- read.csv("data/06-NN/attrition.csv")

head(attrition, 5)
```

```
#>   attrition age   business_travel daily_rate           department
#> 1       yes  41     travel_rarely       1102                sales
#> 2        no  49 travel_frequently        279 research_development
#> 3       yes  37     travel_rarely       1373 research_development
#> 4        no  33 travel_frequently       1392 research_development
#> 5        no  27     travel_rarely        591 research_development
#>   distance_from_home education education_field employee_count employee_number
#> 1                  1         2   life_sciences              1               1
#> 2                  8         1   life_sciences              1               2
#> 3                  2         2           other              1               4
#> 4                  3         4   life_sciences              1               5
#> 5                  2         1         medical              1               7
#>   environment_satisfaction gender hourly_rate job_involvement job_level
#> 1                        2 female          94               3         2
#> 2                        3   male          61               2         2
#> 3                        4   male          92               2         1
#> 4                        4 female          56               3         1
#> 5                        1   male          40               3         1
#>                job_role job_satisfaction marital_status monthly_income
#> 1       sales_executive                4         single           5993
#> 2    research_scientist                2        married           5130
#> 3 laboratory_technician                3         single           2090
#> 4    research_scientist                3        married           2909
#> 5 laboratory_technician                2        married           3468
#>   monthly_rate num_companies_worked over_18 over_time percent_salary_hike
#> 1        19479                    8       y       yes                  11
#> 2        24907                    1       y        no                  23
#> 3         2396                    6       y       yes                  15
#> 4        23159                    1       y       yes                  11
#> 5        16632                    9       y        no                  12
#>   performance_rating relationship_satisfaction standard_hours
#> 1                  3                         1             80
#> 2                  4                         4             80
#> 3                  3                         2             80
#> 4                  3                         3             80
#> 5                  3                         4             80
#>   stock_option_level total_working_years training_times_last_year
#> 1                  0                   8                        0
#> 2                  1                  10                        3
#> 3                  0                   7                        3
#> 4                  0                   8                        3
#> 5                  1                   6                        3
#>   work_life_balance years_at_company years_in_current_role
#> 1                 1                6                     4
#> 2                 3               10                     7
#> 3                 3                0                     0
#> 4                 3                8                     7
#> 5                 3                2                     2
#>   years_since_last_promotion years_with_curr_manager
#> 1                          0                       5
#> 2                          1                       7
#> 3                          0                       0
#> 4                          3                       0
#> 5                          2                       2
```

Kita akan melakukan cross validation, yaitu membagi data menjadi **training set** untuk proses pemodelan dan **testing set** untuk melakukan evaluasi. Namun, data train dan data test tidak langsung dimasukkan ke dalam sebuah objek melainkan dilakukan tahapan data preparation terlebih dahulu yang di dalamnya terdapat tahapan dummy transformation.

Cross validation akan dilakukan dengan menggunakan fungsi `initial_split()` dari library `rsample`. Fungsi tersebut akan melakukan proses sampling untuk cross validation dengan metode **stratified random sampling**, sehingga proporsi target variabel pada data awal, akan dipertahankan baik pada training set maupun testing set.

```r
set.seed(100)

splitted <- initial_split(attrition, prop = 0.8, strata = "attrition")

splitted
```

```
#> <1177/293/1470>
```

Melakukan tahapan data preparation yang didalamnya termasuk melakukan dummy ransformation. Data preparation yang akan dilakukan adalah menghapus variabel yang dianggap tidak berpengaruh, membuang variabel yang variansinya mendekati 0 (tidak informatif), melakukan scaling, dan melakukan dummy transformation. Proses yang dilakukan pada tahapan data preparation akan dilakukan dengan menggunakan fungsi dari library `recipies`, yaitu `step_rm()` untuk menghapus variabel, `step_nzv()` untuk membuang variabel yang variansinya mendekati 0,`step_center()` dan `step_scale()` untuk melakukan scaling, terakhir `step_dummy()` untuk dummy transformation.


```r
rec <- recipe(attrition ~ ., data = training(splitted)) %>% 
  step_rm(employee_count, employee_number) %>%
  step_nzv(all_predictors()) %>% 
  step_center(all_numeric()) %>%
  step_scale(all_numeric()) %>%
  step_dummy(all_nominal(), -attrition, one_hot = FALSE) %>%
  prep()
```

Setelah mendefinisikan proses data preparation pada objek `rec`, selanjutnya proses tersebut diterapkan ke data train menggunakan fungsi `juice()` dan ke data test menggunakan fungsi `bake()` dari library `recipes`.

```r
data_train <- juice(rec)
data_test <- bake(rec, testing(splitted))

head(data_train, 5)
```

```
#> # A tibble: 5 x 45
#>        age daily_rate distance_from_h~ education environment_sat~ hourly_rate
#>      <dbl>      <dbl>            <dbl>     <dbl>            <dbl>       <dbl>
#> 1  4.41e-1      0.747           -1.02    -0.899            -0.633       1.37 
#> 2  8.41e-4      1.42            -0.895   -0.899             1.19        1.27 
#> 3 -1.10e+0     -0.528           -0.895   -1.88             -1.55       -1.28 
#> 4 -5.49e-1      0.505           -0.895   -0.899             1.19        0.633
#> 5  2.42e+0      1.30            -0.772    0.0789            0.281       0.731
#> # ... with 39 more variables: job_involvement <dbl>, job_level <dbl>,
#> #   job_satisfaction <dbl>, monthly_income <dbl>, monthly_rate <dbl>,
#> #   num_companies_worked <dbl>, percent_salary_hike <dbl>,
#> #   performance_rating <dbl>, relationship_satisfaction <dbl>,
#> #   stock_option_level <dbl>, total_working_years <dbl>,
#> #   training_times_last_year <dbl>, work_life_balance <dbl>,
#> #   years_at_company <dbl>, years_in_current_role <dbl>,
#> #   years_since_last_promotion <dbl>, years_with_curr_manager <dbl>,
#> #   attrition <fct>, business_travel_travel_frequently <dbl>,
#> #   business_travel_travel_rarely <dbl>, department_research_development <dbl>,
#> #   department_sales <dbl>, education_field_life_sciences <dbl>,
#> #   education_field_marketing <dbl>, education_field_medical <dbl>,
#> #   education_field_other <dbl>, education_field_technical_degree <dbl>,
#> #   gender_male <dbl>, job_role_human_resources <dbl>,
#> #   job_role_laboratory_technician <dbl>, job_role_manager <dbl>,
#> #   job_role_manufacturing_director <dbl>, job_role_research_director <dbl>,
#> #   job_role_research_scientist <dbl>, job_role_sales_executive <dbl>,
#> #   job_role_sales_representative <dbl>, marital_status_married <dbl>,
#> #   marital_status_single <dbl>, over_time_yes <dbl>
```

Setelah melakukan dummy transformation pada pediktor, data train dan test harus disesuaikan bentuknya untuk melalui proses building model dengan metode neural network. Target variabel yang bertipe kategorik akan dilakukan dummy transformation dengan menggunakan fungsi `to_categorical()` dari library keras, sementara semua prediktor akan diubah ke dalam bentuk matriks numerik.

```r
# menyiapkan data train
data_train_y <- to_categorical(as.numeric(data_train$attrition) - 1)

data_train_x <- data_train %>% 
  select(-attrition) %>% 
  data.matrix()

# menyiapkan data test
data_test_y <- to_categorical(as.numeric(data_test$attrition) - 1)

data_test_x <- data_test %>% 
  select(attrition) %>% 
  data.matrix()

# cek data train dan test
dim(data_train_x)
```

```
#> [1] 1177   44
```

```r
dim(data_train_y)
```

```
#> [1] 1177    2
```

8. Ketika running model NN weight/bobot diinisialisasi secara random sehingga menyebabkan hasil yang berbeda jika dilakukan berulang kali. Bagaiamana cara mengatur/menggunakan seed pada Neural Network?

Metode neural network selalu menginisialisasi bobot/weight secara random di awal, sehingga ketika metode tersebut di running berulang kali akan memperoleh hasil yang berbeda. Untuk mengatasi hal tersebut kita dapat menggunakan seed (state random). Kita dapat menentukan seed dengan menggunakan fungsi `use_session_with_seed()` dari library `keras`.

```r
use_session_with_seed(seed)
```

Selain menggunakan cara di atas kita juga dapat menggunakan seed dengan fungsi `initializer_random_normal()`. Berikut cara menggunakan seed dengan fungsi tersebut.

```r
# define seed
set.seed(100)
initializer <- initializer_random_normal(seed = 100)

# use the seed when building architecture
model <- keras_model_sequential() %>% 
  layer_dense(units = ..., 
              activation = "...", 
              input_shape = c(...),
              kernel_initializer = initializer, 
              bias_initializer = initializer)
```
