# Neural Network and Deep Learning



1. Berapa jumlah hidden layer dan nodes untuk setiap hidden layer secara best practice dalam membangun arsitektur neural network (ANN) ?

- Kebanyakan orang menggunakan minimal 2 hidden layer, namun tidak menutup kemungkinan menggunakan lebih dari 2 ataupun kurang dari 2 hidden layer.
- Jumlah nodes biasanya semakin mengecil ketika hidden layers semakin dekat dengan output layer. Tujuannya adalah untuk melihat fitur dengan lebih spesifik. 
- Kebanyakan orang menggunakan angka biner $2^{n}$ seperti 1, 2, 4, 8, 16, 32, 64, 128, 256, dst karena neural network merupakan metode yang berasal dari orang computer science dan mathematics yang biasa menggunakan angka biner.

2. Fungsi aktivasi apa yang sering digunakan ketika membuat arsitktur neural network ?

- Pada hidden layer biasa digunakan fungsi aktivasi `relu` karena `relu` melakukan transformasi data dengan mengubah nilai negatif menjadi 0 dan membiarkan nilai positif, sehingga semakin ke belakang informasi yang dibawa tidak banyak berkurang.
- Pada output layer: jika casenya adalah regresi digunakan fungsi aktivasi `linear`, jika casenya adalah klasifikasi biner digunakan fungsi aktivasi `sigmoid`, dan jika casenya adalah klasifikasi multiclass digunakan fungsi aktivasi `softmax`.

3. Bagaimana menentukan batch size dan jumlah epoch ?

- Batch size biasanya menggunakan angka yang dapat membagi habis jumlah data, supaya data yang tersedia dapat digunakan secara keseluruhan (tidak ada yang tidak terpakai). Contoh:
Jika data train terdiri dari 800 observasi, kita bisa menggunakan batch size 200 yang dapat embagai habis 80 observasi.
- Jumlah epoch dimulai dari angka yang kecil terlebih dahulu supaya komputasi yang dilakukan tidak terlalu lama, kemudian dilihat apakah error dan accuracy yang dhasilkan sudah konvergen atau belum. Jika belum bisa menambaha jumlah epoch sedikit demi sedikit, dan sebaliknya.

4. Bagaimana menentukan learning rate yang tepat ?

   Learning rate berfungsi mempercepat atau memperlambat besaran update error.

- Semakin besar learning rate, maka error/accuracy akan semakin cepat konvergen. Namun, bisa saja titik error paling minimum (global optimum) terlewat.
- Semakin kecil learning rate, maka terdapat kemungkinan yang lebih besar untuk sampai di titik error paling minimum (global optimum). Namun, error/accuracy akan lebih lama konvergen.

5. Optimizer apa yang paling sering digunakan ?

   Optimizer merupakan fungsi yang digunakan untuk mengoptimumkan error (memperkecil error). Secara sederhana untuk mengoptimumkan suatu fungsi bisa melalui fungsi turunan, pada neural network disebut `sgd.` Namun, `sgd` memiliki beberapa kekurangan sehingga mulai banyak yang memperbaiki fungsi `sgd` tersebut. Untuk sekarang ini salah satu optimizer yang cukup terkenal adalah `adam` sebagai optimizer yang merupakan perbaikan dari `sgd` karena optimizer tersebut dapat mengupdate/menyesuaikan momentum ketika proses optimisasi. Berikut link eksternal yang dapat dijadikan sebagai bahan referensi [Adaptive Moment Estimation (Adam)](https://ruder.io/optimizing-gradient-descent/index.html#adam)

   Selain tips di atas berikut link eksternal yang dapat dijadikan referensi dalam membangun arsitektur neural network [Rules-of-thumb for building a Neural Network](https://towardsdatascience.com/17-rules-of-thumb-for-building-a-neural-network-93356f9930af)

6. Perbedaan metode-metode machine learning dengan neural network dan deep learning ?

- Neural network bukan merupakan metode yang berasal dari orang statistik melainkan lahir dari pemikiran orang-orang computer science dan math.
- Neural network merupakan salah satu metode machine learning, neural network yang arsitekturnya sudah cukup rumit sering disebut sebagai deep learning. Neural network memilki `1` hidden layer, sementara deep learning memiliki `> 1` hidden layer.

   Berikut merupakan link eksternal yang dapat dijadikan sebagai bahan referensi [Deep learning & Machine learning: whatâ€™s the difference?](https://parsers.me/deep-learning-machine-learning-whats-the-difference/)


